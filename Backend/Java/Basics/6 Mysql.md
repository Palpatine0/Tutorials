### 概述

#### 基础架构

<img src="https://i.loli.net/2021/02/12/dtLgqGebU4RDmyM.png" alt="img" style="zoom: 80%;" />

- Server层：所有跨存储引擎的功能都在这一层实现，如存储过程、触发器、视图，函数等，还有一个通用的binglog日志模块。
  - 连接器：与登录时的身份认证和权限相关

  - 查询缓存：主要用来缓存所执行的 SELECT 语句以及结果集。数据以 Key-Value 的形式缓存在内存中，Key 是查询预计，Value 是结果集。缓存命中则直接返回结果，查询结束。

    MySQL查询不建议使用缓存，8.0 版本后删除。因为查询缓存失效在实际业务场景中可能会非常频繁，假如你对一个表更新的话，这个表上的所有的查询缓存都会被清空。

  - 分析器

    - 词法分析：提取关键字如 select、查询的表、字段名、查询条件等
    - 语法分析：主要判断输入的 sql 是否符合 MySQL 语法

  - 优化器：确定执行计划，按 MySQL 认为的最优方案去执行

  - 执行器：先校验用户操作权限，没有权限就会返回错误信息；有权限就调用引擎的接口，返回接口执行的结果。

- 存储引擎层：主要负责数据的存储和读取，采用可以替换的插件式架构，支持 InnoDB、MyISAM等多个存储引擎

**SQL语句在MySQL中如何执行的？**

**1 查询语句**

- 连接器先检查该语句是否有权限，如果没有权限，直接返回错误信息。
- 如果有权限，在 MySQL8.0 版本以前，会先查询缓存。
- 如果没有缓存，分析器进行词法分析，提取select等关键元素。然后判断sql 语句是否有语法错误，比如关键词是否正确等等。
- 优化器进行确定执行方案
- 执行器进行用户权限校验，如果没有权限就直接返回错误信息，如果有权限就会调用数据库引擎接口，返回执行结果。

**2 更新语句**

- 获取更新前表中数据……
- 更新数据，两阶段提交……

#### 存储引擎

存储引擎Storage engine：是数据库底层软件，数据库管理系统使用存储引擎创建、查询、更新和删除数据。

- Innodb引擎（Mysql5.5后默认）
- MyIASM引擎(原本Mysql的默认引擎)
- MEMORY引擎：所有的数据都在内存中，数据的处理速度快，但是安全性不高。

**MyISAM与InnoDB区别**⭐

- InnoDB支持表锁和行锁；MyISAM只支持表锁

- InnoDB支持事务；MyISAM不支持事务

- InnoDB必须有主键；MyISAM可以没有主键

- InnoDB支持外键；MyISAM不支持外键

- InnoDB按主键大小有序插入，MyISAM按记录插入顺序保存

- MyISAM批量插入速度快

- InnoDB表需要更多的内存；MyISAM可被压缩，所需内存小

- > InnoDB不支持全文索引；MyISAM支持全文索引（5.7以后的InnoDB也支持全文索引）

|                                                              | MyISAM                                                       | Innodb                                                       |
| ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 存储结构                                                     | 每张表被存放在三个文件：frm-表格定义、MYD(MYData)-数据文件、MYI(MYIndex)-索引文件 | 所有的表都保存在同一个数据文件中（也可能是多个文件，或者是独立的表空间文件），InnoDB表的大小只受限于操作系统文件的大小，一般为2GB |
| 存储空间                                                     | MyISAM可被压缩，存储空间较小                                 | InnoDB的表需要更多的内存和存储，它会在主内存中建立其专用的缓冲池用于高速缓冲数据和索引 |
| 可移植性、备份及恢复                                         | 由于MyISAM的数据是以文件的形式存储，所以在跨平台的数据转移中会很方便。在备份和恢复时可单独针对某个表进行操作 | 免费的方案可以是拷贝数据文件、备份 binlog，或者用 mysqldump，在数据量达到几十G的时候就相对痛苦了 |
| 文件格式                                                     | 数据和索引是分别存储的，数据`.MYD`，索引`.MYI`               | 数据和索引是集中存储的，`.ibd`                               |
| 记录存储顺序                                                 | 按记录插入顺序保存                                           | 按主键大小有序插入                                           |
| 外键                                                         | 不支持                                                       | 支持                                                         |
| 事务                                                         | 不支持                                                       | 支持                                                         |
| 锁支持（锁是避免资源争用的一个机制，MySQL锁对用户几乎是透明的） | 表级锁定                                                     | 行级锁定、表级锁定，锁定力度小并发能力高                     |
| SELECT                                                       | MyISAM更优                                                   |                                                              |
| INSERT、UPDATE、DELETE                                       |                                                              | InnoDB更优                                                   |
| select count(*)                                              | myisam更快，因为myisam内部维护了一个计数器，可以直接调取。   |                                                              |
| 索引的实现方式                                               | B+树索引，myisam 是堆表                                      | B+树索引，Innodb 是索引组织表                                |
| 哈希索引                                                     | 不支持                                                       | 支持                                                         |
| 全文索引                                                     | 支持                                                         | 不支持                                                       |

**存储引擎选择**

如果没有特别的需求，使用默认的`Innodb`即可。

- MyISAM：以读写插入为主的应用程序，比如博客系统、新闻门户网站。
- Innodb：更新（删除）操作频率也高，或者要保证数据的完整性；并发量高，支持事务和外键。比如OA自动化办公系统。

#### 数据库连接池

**什么是数据库连接池？**

在程序初始化时创建一定数量的数据库连接对象并将其保存在一块内存区中。维护一定数量的数据库连接，并对外暴露数据库连接的获取和返回方法。

**数据库连接池好处**

- 更快的系统响应速度
- 资源重用 (连接复用)
- 统一的连接管理，避免数据库连接泄露

**常见数据库连接池**

- c3p0
- HikariCP：目前业内最快的数据库连接池。
- Druid：性能测试过程略低雨HikariCP，但是提供了强大的监控和扩展功能

### 特性

#### 三大范式

**数据库三大范式是什么**

- 第一范式：每个列**不可拆分**
- 第二范式：在第一范式的基础上，非主键列**完全依赖**于主键，而不能是依赖于主键的一部分
- 第三范式：在第二范式的基础上，非主键列**只依赖**于主键，不依赖于其他非主键

在设计数据库结构的时候尽量遵守三范式，事实上我们经常会为了性能而妥协数据库的设计

#### 日志⭐

**1 二进制日志(binlog)**

- 作用：主从复制、基于时间点的恢复
- 内容：逻辑格式，记录sql语句的相关信息。三种录入格式
- 什么时候产生：事务提交时，一次性将事务中的sql语句记录到binlog中。故在开启了bin_log的情况下，对于较大事务的提交，可能会变得比较慢一些。
- 什么时候释放：默认保持时间由参数expire_logs_days配置。对于非活动的日志文件，在生成时间超过expire_logs_days配置的天数之后，会被自动删除。

**MySQL的binlog有几种录入格式？分别有什么区别？**

- statement：记录修改数据的sql语句。减少了binlog日志量，节约了IO，提高性能。由于sql的执行是有上下文的，因此在保存的时候需要保存相关的信息，同时还有一些使用了函数之类的语句无法被记录复制。
- row：仅记录哪条记录被修改。记录单元为每一行的改动，但很多操作会导致大量的改动(比如alter table)，因此文件保存的信息太多，日志量太大。此外，新版的MySQL中对row级别也做了一些优化，当表结构发生变化的时候，会记录语句而不是逐行记录。
- mixed：折中方案，普通操作使用statement记录，无法使用statement时使用row。

---

redo log和undo log都属于InnoDB的事务日志。

**2 重做日志(redo log)**

- 作用：用于崩溃恢复，保证事务的**持久性**——两阶段提交
- 内容：**物理格式**，记录物理页的修改信息
- 什么时候产生：事务的执行过程中便开始写入redo log文件
- 什么时候释放：对应事务的脏页写入到磁盘后，重做日志占用的空间就可以重用（被覆盖）

**数据更新与 redo log 两阶段提交 / Innodb 是怎么保证崩溃恢复能力的 / crash safe**⭐ [参考](https://www.cnblogs.com/kiwi-deng/p/13641783.html) [参考](https://blog.csdn.net/qq_38937634/article/details/113100472)

<img src="https://i.loli.net/2021/06/16/mKa4dWPSOjuLDV2.png" alt="image-20210616232322660" style="zoom: 67%;" />

修改数据时将redo log的写入拆成两个步骤：prepare 和 commit

- 执行器先查询数据……
- 执行器修改数据，然后写入新数据
- **prepare阶段**：存储引擎将数据更新到内存，同时写数据到redo log。redo log处于 prepare 状态
- **commit阶段**：执行器写数据到 binlog 中，最后存储引擎提交事务。redo log处于 commit 状态

**采用二阶段提交的原因** [参考](https://blog.csdn.net/weixin_41796257/article/details/108934919) 

如果不使用“两阶段提交”而直接写redo log，那么数据库的状态就有可能和用它的日志恢复出来的库的状态不—致

- 先写redo log再写binlog

  如果在一条语句写入redo log后崩溃了，则binlog没有记录这条语句。crash recovery时重新执行binlog便会少了这一次的修改。

- 先写binlog再写redo log

  如果在一条语句写入binlog后崩溃了，则redolog没有记录这条语句。crash recovery时重新执行binlog便会多了这一次的修改。

**Crash recovery的3种情况**

- binlog有记录，redolog状态commit：正常完成的事务，不需要恢复；
- binlog有记录，redolog状态prepare：在binlog写完提交事务之前的crash，提交事务。（因为之前没有提交）
- binlog无记录，redolog状态prepare：在binlog写完之前的crash，回滚事务（因为crash时并没有成功写入数据库）

**redo log 与 binlog 的区别**⭐

- 层次不同：redo log基于InnoDB存储引擎实现；binlog基于MySQL服务器层实现
- 内容不同：redo log是物理日志，记录物理页的修改信息；binlog是逻辑日志，记录sql语句的相关信息
- 作用不同：redo log用于崩溃恢复，保证事务的持久性；binlog用于主从复制、时间点恢复
- 恢复效率：基于物理日志的redo log的恢复效率要高于基于逻辑日志的binlog
- 空间不同：redo log 循环写，会覆盖以前的记录；binlog 追加写，会切换到下一页而不会覆盖以前的记录

> redo log和binlog可以相互替代或者只保留其一吗？[参考](https://blog.csdn.net/daijiguo/article/details/104982890) 
>
> - binlog肯定要有，因为redo log只基于InnoDB存储引擎实现
> - redo log对InnoDB也要有，主要是是事务恢复

---

**3 回滚日志(undo log)**

- 作用：保证事务的**原子性和隔离性**：保存了**事务发生之前**的数据版本用于回滚，并提供**MVCC**

- 内容：逻辑格式，记录sql语句的相关信息。回滚时根据undo log的内容做与之前相反的工作

- 什么时候产生：事务开始之前生成当前版本的 undo log，也会产生 redo 来保证自身的可靠性。

  默认情况下undo文件是保持在共享表空间的，即ibdatafile文件。因此共享表空间可能会变的很大，默认情况下被“撑大”的共享表空间是不会也不能自动收缩的。

- 什么时候释放：事务提交后，undo log不能立即删除，而是放入待清理的链表，由purge线程判断是否有其他事务在使用undo的信息，决定是否可以清理undo log。

**事务提交的过程**

- 事务在修改数据页前要先记 undo，两阶段提交……
- 崩溃恢复时，两阶段提交……

#### InnoDB四大特性

**1 插入缓冲(insert Buffer)** [参考](https://blog.csdn.net/weixin_30426065/article/details/94934123)

在MySQL5.5之前，叫插入缓冲(insert buffer)，只针对insert做了优化；现在对delete和update也有效，叫写缓冲(change buffer)

非聚集索引的插入不是直接写到索引页中，而是先判断索引页是否在**缓冲池**中：若在则直接插入；若不在则先放到 **Insert Buffer** 中，再按照一定的频率进行合并操作，最后写回磁盘。这样通常能将多个插入合并到一个操作，减少随机IO带来性能损耗。

<img src="https://img-blog.csdn.net/20171104193622911?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbG9uZ2RheXU0NTQ0/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" style="zoom: 50%;" />

**2 二次写(double write)**

使用redo log前需要页的副本，写入失败则先通过页的副本来还原页

组成：

- 内存中的doublewrite buffer，大小2M。

- 物理磁盘上共享表空间中连续的128个页，即2个区（extend），大小同样为2M。

对缓冲池的脏页进行刷新时，步骤如下：

- 通过memcpy()函数将脏页先复制到内存中的doublewrite buffer，
- 之后通过doublewrite再分两次，每次1M顺序地写入共享表空间的物理磁盘上，在这个过程中，因为doublewrite页是连续的，因此这个过程是顺序写的，开销并不是很大。
- 再将doublewrite buffer 中的页写入各个表空间文件中，此时的写入则是离散的。

如果操作系统在将页写入磁盘的过程中发生了崩溃，在恢复过程中，innodb可以从共享表空间中的doublewrite中找到该页的一个副本，将其复制到表空间文件，再应用重做日志。

<img src="https://i.loli.net/2021/02/12/Pc7XDLYlyAvE1md.png" alt="img" style="zoom: 67%;" />

**3 自适应哈希(ahi)**

innodb会监控对表上个索引页的查询。如果观察到建立哈希索引可以带来速度提升，则自动建立哈希索引，经常访问的二级索引数据会自动被生成到hash索引里面去（最近连续被访问三次的数据）。自适应哈希索引通过缓冲池的B+树构造而来，因此建立的速度很快。

特点：

- 自适应
- 无序，没有树高
- 降低对二级索引树的频繁访问资源

缺陷：

- hash自适应索引会占用innodb buffer pool
- 自适应hash索引只适合搜索等值的查询，不能用于其他查找如范围查找

**4 预读(read ahead)**

使用两种预读算法来提高I/O性能：线性预读（linear read-ahead）和随机预读（randomread-ahead）

- 线性预读以extent（区）为单位；随机预读放到以page（页）为单位
- 线性预读将下一个extent提前读取到buffer pool中；随机预读将当前extent中的page提前读取到buffer pool中

### SQL语句

#### SQL概述

**什么是SQL？**

结构化查询语言(Structured Query Language)简称SQL，是一种数据库查询语言。

作用：用于存取数据、查询、更新和管理关系数据库系统。

**SQL语句主要分为哪几类**

- 数据定义语言DDL（Data Ddefinition Language）CREATE，DROP，ALTER

  即对逻辑结构等有操作的，其中包括表结构，视图和索引。

- 数据查询语言DQL（Data Query Language）SELECT

   即查询操作，以select关键字。各种简单查询，连接查询等都属于DQL。

- 数据操纵语言DML（Data Manipulation Language）INSERT，UPDATE，DELETE

  即常用的增删改查操作。

- 数据控制功能DCL（Data Control Language）GRANT，REVOKE，COMMIT，ROLLBACK

  即对数据库安全性完整性等有操作的，可以简单的理解为权限控制等。

#### 数据类型

**mysql有哪些数据类型**

| **分类**         | **类型名称**     | **说明**                                                     |
| ---------------- | ---------------- | ------------------------------------------------------------ |
| 整数类型         | **tinyInt**      | 很小的整数(8位二进制)                                        |
|                  | smallint         | 小的整数(16位二进制)                                         |
|                  | mediumint        | 中等大小的整数(24位二进制)                                   |
|                  | **int**(integer) | 普通大小的整数(32位二进制)                                   |
| 小数类型         | **float**        | 单精度浮点数                                                 |
|                  | **double**       | 双精度浮点数                                                 |
|                  | **decimal**(m,d) | 压缩严格的定点数                                             |
| 日期类型         | year             | YYYY 1901~2155                                               |
|                  | time             | HH:MM:SS -838:59:59~838:59:59                                |
|                  | date             | YYYY-MM-DD 1000-01-01~9999-12-3                              |
|                  | **datetime**     | YYYY-MM-DD HH:MM:SS 1000-01-01 00:00:00~ 9999-12-31 23:59:59 |
|                  | **timestamp**    | YYYY-MM-DD HH:MM:SS 19700101 00:00:01 UTC~2038-01-19 03:14:07UTC |
| 文本、二进制类型 | **CHAR**(M)      | M为0~255之间的整数                                           |
|                  | **VARCHAR**(M)   | M为0~65535之间的整数                                         |
|                  | TINYBLOB         | 允许长度0~255字节                                            |
|                  | **BLOB**         | 允许长度0~65535字节                                          |
|                  | MEDIUMBLOB       | 允许长度0~167772150字节                                      |
|                  | LONGBLOB         | 允许长度0~4294967295字节                                     |
|                  | TINYTEXT         | 允许长度0~255字节                                            |
|                  | **TEXT**         | 允许长度0~65535字节                                          |
|                  | MEDIUMTEXT       | 允许长度0~167772150字节                                      |
|                  | LONGTEXT         | 允许长度0~4294967295字节                                     |
|                  | VARBINARY(M)     | 允许长度0~M个字节的变长字节字符串                            |
|                  | BINARY(M)        | 允许长度0~M个字节的定长字节字符串                            |

**varchar与char的区别**⭐

- varchar表示可变长字符串；char表示定长字符串
- varchar插入数据多长就存储多长；char插入数据小于的固定长度时，用空格填充
- varchar存取慢；char存取快
- varchar最多能存放65532个字符；char最多能存放255个字符

使用策略

- 变更的数据CHAR比VARCHAR更好，因为CHAR不容易产生碎片。
- 非常短的列CHAR比VARCHAR在存储空间上更有效率。

**int(10)和char(10)以及varchar(10)的区别**

- int(10)表示显示数据的长度为10，但仍占4个字节

- char(10)表示存储定长的10个字符，不足就用空格补齐，多了
- varchar(10)表示存储10个变长字符，不足存储多少个就是多少个，多了截断

**varchar(50)中50的涵义**

在早期 MySQL 版本中代表字节数，现在代表**字符数**。

> 一个汉字一个字符、utf-8**三个字节**
>
> varchar(50)和varchar(200)存储hello空间一样，但后者在排序时会消耗更多内存，因为order by col采用fixed_length计算col长度

**Blob和text有什么区别？**

- Blob用于存储**二进制**数据；Text用于存储大字符串。
- Blob没有字符集，排序和比较基于字节的数值；text有字符集，排序和比较基于字符集的规则

**字段为什么要求定义为not null？**

- null值需要额外的标志位，会占用更多的字节
- 索引难以优化。含有null值的列虽然能走索引，但很难进行查询优化，因为其使得索引、索引的统计信息以及比较运算更加复杂。
- NOT IN、!= 等负向条件查询在有 NULL 值的情况下返回永远为空结果，查询容易出错。
- 使用NULL值的情况都可以通过一个有意义的值的表示，有利于代码的可读性和可维护性

**小数类型**

- FLOAT和DOUBLE支持使用浮点进行近似计算。
- 计算时FLOAT和DOUBLE相比DECIMAL效率更高一些，DECIMAL可以理解成用字符串进行处理。

**MySQL中DATETIME和TIMESTAMP的区别**

存储精度都为秒

- DATETIME 的存储空间为 8 字节；TIMESTAMP 的存储空间为 4 字节
- DATETIME 的日期范围是 1001——9999 年；TIMESTAMP 的时间范围是 1970——2038 年
- DATETIME 存储时间与时区无关；TIMESTAMP 存储时间与时区有关
- DATETIME 的默认值为 null；TIMESTAMP 的字段默认值为当前时间戳(CURRENT_TIMESTAMP)
- 尽量使用TIMESTAMP，空间效率高于DATETIME 

#### 执行顺序

![img](https://i.loli.net/2021/02/12/kljIJbXPtyrpweB.jpg)

#### 子句

**mysql中 in 和 exists 区别 **⭐ [参考](https://blog.csdn.net/jinjiniao1/article/details/92666614)

- in查询先将子查询全都查出，每条记录再对外表进行全表扫描；

  exists查询对外表作逐条查询，每次查询都会比对exists的条件语句，满足则保留，反之丢弃；

- in在内部表和**外部表**上都可以使用到索引；exists仅在内部表上可以使用到索引

- 子查询结果集较小外部表很大时，IN 的外表索引占主要作用，查询效率优于Exists。（子小外大）

  子查询结果集很大外部表较小时，Exists的嵌套循环能弥补外部表无法用到索引的缺陷，查询效率会优于IN （子大外小）

  > 表的规模不是看内部表和外部表的大小，而是看其结果集。

**drop、delete与truncate的区别**

|          | Delete                   | Truncate           | Drop         |
| -------- | ------------------------ | ------------------ | ------------ |
| 删除内容 | 删除表的全部或者一部     | 删除表中的所有数据 | 删除整个表   |
| 删除速度 | 删除速度慢，需要逐行删除 | 删除速度中         | 删除速度最快 |
| 类型     | 属于DML                  | 属于DDL            | 属于DDL      |
| 回滚     | 可回滚                   | 不可回滚           | 不可回滚     |

**UNION与UNION ALL的区别？**

- Union：对两个结果集进行并集操作且去重；进行排序（按select查找的字段升序）；索引不会生效性能较差，经常用or替换
- Union All：对两个结果集进行并集操作而不去重；不进行排序；索引生效性能较好，尽量使用

#### 关联查询

**六种关联查询**

- 内连接（INNER JOIN）
- 外连接（LEFT JOIN/RIGHT JOIN）：左连接、右连接
- 联合查询（UNION与UNION ALL）
- 全连接（FULL JOIN）
- 交叉连接（CROSS JOIN）：即笛卡尔积

**mysql的内连接、左连接、右连接有什么区别？**⭐

- Inner join：内连接。两张表进行连接查询时，只保留两张表中完全匹配的记录
- left join：左连接。两张表进行连接查询时，会返回左表所有的行，即使在右表中没有匹配的记录。
- right join：右连接。两张表进行连接查询时，会返回右表所有的行，即使在左表中没有匹配的记录。

**连接查询的底层实现**⭐ [参考](https://blog.csdn.net/zhou307/article/details/104158664?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522161746130116780266235233%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fall.%2522%257D&request_id=161746130116780266235233&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_v2~rank_v29-1-104158664.pc_search_result_cache&utm_term=%E5%85%B3%E8%81%94%E6%9F%A5%E8%AF%A2%E5%BA%95%E5%B1%82) [参考](https://oatlmy.blog.csdn.net/article/details/104172743)

`from a (inner/left/right) join b`

- 无索引：笛卡尔积，把a中每一行的数据都在b中全表扫描

- 有索引：对a中每一行的数据，走b的索引而不用全表扫描

### 索引

#### 索引概述⭐

**什么是索引？**

- MySQL官方对索引的定义为：索引是帮助MySQL高效获取数据的数据结构。通俗的说，索引就相当于目录，方便查找书中的内容
- 索引是一种存放在磁盘上的文件，InnoDB存储引擎默认将索引文件和数据文件放在.ibd文件

**索引优点 / 为什么要使用索引**

- 可以加快数据的查询速度
- 可以加快数据的排序操作
- 可以加快表之间的连接
- 唯一索引可以保证表中每行数据的唯一性

> 索引可以避免无索引行锁升级为表锁

**索引缺点 / 索引这么多优点，为什么不对表中的每一个列创建一个索引呢？**

- 时间：创建索引和数据增删改时维护索引要耗费时间
- 空间：索引需要占物理空间

#### 索引原理⭐

**磁盘IO与预读**

磁盘读取数据靠的是机械运动，每次读取数据花费的时间可以分为寻道时间、旋转延迟、传输时间三个部分，开销巨大

由**局部性原理**知，计算机访问一个地址的数据的时候，与其相邻的数据也会很快被访问到。故一次IO不光把当前磁盘地址的数据，而是把相邻的数据也都读取到内存缓冲区内，每一次IO读取的数据我们称之为**一页**(page)。具体一页有多大数据跟操作系统有关，一般为4k或8k

---

**二叉查找树(AVL)** [参考](https://blog.csdn.net/b_x_p/article/details/86434387)

左小右大。但插入数据有序时，会形成线性链表。

---

**平衡二叉树**

节点的子节点高度差不能超过1，解决了形成线性链表的问题。但没有利用好磁盘I预读能力，每个节点不能够填满4K的内容，造成浪费

<img src="https://img-blog.csdnimg.cn/20200516171035521.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2JfeF9w,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" style="zoom: 40%;" />



---

**B树**

一个绝对平衡树，所有的叶子节点在同一高度。很好的利用操作系统和磁盘的数据交换特性以及磁盘IO的预读能力，将页大小设置为**16K**，即将一个节点（磁盘块）的大小为16K，一次IO将一个节点的内容加载进内存。

但非叶子节点也有数据，树高较大。

> 假设关键字类型为 int 4字节，若每个关键字对应的数据区也为4字节，不考虑子节点引用的情况下，则上图中的每个节点大约能够存储（16 * 1000）/ 8 = 2000个关键字，共2001个路数。对于二叉树，三层高度，最多可以保存7个关键字，而对于这种有2001路的B树，三层高度能够搜索的关键字个数远远的大于二叉树。

**m阶B树满足以下条件**

- 每个节点至多可以拥有m棵子树。
- 根节点，只有至少有2个节点（要么极端情况，就是一棵树就一个根节点，单细胞生物，即是根，也是叶，也是树)。
- 非根非叶的节点至少有的Ceil(m/2)个子树(Ceil表示向上取整，图中5阶B树，每个节点至少有3个子树，也就是至少有3个叉)。
- 非叶节点中的信息包括[n,A0,K1,A1,K2,A2,…,Kn,An]，，其中n表示该节点中保存的关键字个数，K为关键字且Ki<Ki+1，A为指向子树根节点的指针。
- 从根到叶子的每一条路径都有相同的长度，也就是说，叶子节在相同的层，并且这些节点不带信息，实际上这些节点就表示找不到指定的值，也就是指向这些节点的指针为空。

<img src="https://img-blog.csdnimg.cn/20200516172313521.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2JfeF9w,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" style="zoom:40%;" />

**B树有哪些使用场景？**

B树的使用场景：MongoDB

---

**B+树索引**

**B+tree性质**

- n棵子tree的节点包含n个关键字，不用来保存数据而是保存数据的索引
- 所有的叶子结点中包含了全部关键字的信息，及指向含这些关键字记录的指针，且叶子结点本身依关键字的大小自小而大顺序链接
- 所有的非终端结点可以看成是索引部分，结点中仅含其子树中的最大（或最小）关键字
- B+树中，数据对象的插入和删除仅在叶节点上进行
- B+树有2个头指针，一个是树的根节点，一个是最小关键码的叶节点

<img src="https://img-blog.csdnimg.cn/20200516191817713.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2JfeF9w,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" style="zoom: 33%;" />

**B+树一般一个节点有几个子节点？B+树有几层？为什么？B+树查找过程的I/O次数是怎么算的 **[参考](https://zhuanlan.zhihu.com/p/86137284)  [参考](https://blog.csdn.net/LJFPHP/article/details/97133701)

B+ 树高度一般为 2-4 层，3层就能满足千万级的数据存储。一层读一个结点即一页即一次IO

- 一个节点 = 一页 = 16k
  - 非叶子节点：设主键 id 为 bigint 类型 8 字节，而指针在源码中设置为 6 字节，共 14 字节。16k/14字节=1170个指针节点
  - 叶子节点：假设一行记录的数据大小为 1k，则一个节点有16行记录
- 2层B+树可存 1170 * 16=18720条记录 1w+
- 3层B+树可存 1170 * 1170 * 16=21902400条记录 2000w+

**为什么用B+树 / b+树的优点**⭐

- B+树查询效率更高。B+树非叶子结点没有存储数据信息，一个结点可读入的关键字更多，树的高度更低，IO次数更少。
- B+树的查询更稳定。B+树查询是从根节点到叶子节点，每个关键字的查询效率相当；B树越靠近根节点的记录查找时间越短
- B+树增删效率更高。B+树叶子节点包含所有关键字，并以有序链表存储，便于增删
- B+树支持顺序查询。B+树叶子节点顺序排列且相邻节点顺序引用
- B+树支持范围查询。B+树只要遍历叶子节点就可以实现整棵树的遍历，实现范围查询

**为什么B+树比红黑树要好**

很多可以参考上一题，不过考的概率很低

**B+树上查询数据的流程？**

数据检索规则是左闭右合，路数和关键个数关系为1比1。对一个数……（看图瞎扯）

**B+树的时间复杂度为什么是log（N） **[参考](https://blog.csdn.net/m0_37313888/article/details/105681539)

每层平均遍历m/2，每层向下log(m)n，所以一共是(m/2) * log(m)n。由于m是常数？所以复杂度为O(log n)

计算：O((m/2) * log(m)n) = O(m * log(m)n)  = O(log(m的1/m次方)n)

**InnoDB为什么推荐使用自增ID作为主键？/ 自增 ID 和 UUID 的区别**

自增ID可以保证每次插入时B+索引是从右边扩展的，避免B+树结点频繁合并和分裂。

**自增主键用完了怎么办？ **[参考](https://blog.csdn.net/qq_35393693/article/details/100059966)

> 自增id达到最大值时，继续插入会报一个**主键冲突异常** //Duplicate entry '4294967295' for key 'PRIMARY'

- 可以将int改为bigint，修改时借助第3方工具或主从切换等
- 其实一旦自增主键用完了，说明此时数据量已经很大（近20亿）！早就分库分表了，而分库分表了就不再使用自增ID

**组合索引是什么？为什么需要注意组合索引中的顺序？**

组合索引：在多个列上建立的索引

因为InnoDB引擎中的索引策略的最左原则，所以需要注意组合索引中的顺序。

**什么是最左前缀原则？**⭐

- 定义：顾名思义就是最左优先，mysql会一直向右匹配直到遇到范围查询(>、<、between、like)为止。

  比如a = 1 and b = 2 and c > 3 and d = 4 如果建立(a,b,c,d)顺序的索引，c为范围查询停止匹配，abc用到索引，d用不到索引

- 原理：b+ 树按索引建立的顺序从左到右建立搜索树。

  如(a,b,c,d)索引，b+ 树会优先比较 a 来确定下一步的所搜方向，如果 a 相同再依次比较 b 和 c ，最后得到检索的数据。反之……

- 使用：在创建组合索引时，要根据业务需求，把where子句中使用最频繁的一列放在最左边；

  =和in可以乱序，mysql的优化器帮助优化成索引可以识别的形式：如a = 1 and b = 2 and c = 3 建立(a,b,c)索引可以任意顺序

**覆盖索引 回表 索引下推**⭐

- 覆盖索引：查询的字段都被索引覆盖，可直接在索引中查询而不用回表

- 回表：二级索引无法直接查询到所有列的数据，所以通过二级索引查询到主键id后，再去遍历聚集索引。

  - 二级索引直接查询主键id，是顺序IO
  - 拿到主键id之后，这些主键id可能并不是顺序排列的，还要用主键去查询聚簇索引，是随机IO

- 索引下推ICP：Mysql5.6推出，用于优化**部分生效的非聚簇索引**[参考](https://www.cnblogs.com/Chenjiabing/p/12600926.html)。可以减少回表次数及数据传输量，优化性能。 

  不使用ICP时，存储引擎将通过索引搜索数据，然后返回数据给MySQL服务器，**由MySQL服务器再判断是否符合条件。**

  ![image-20210313230048042](https://i.loli.net/2021/03/13/fAmlpCeSMWDy8YO.png)

  使用ICP时，MySQL服务器将把索引列的判断条件传递给存储引擎，**由存储引擎判断是否符合条件**，然后返回数据给MySQL服务器

  ![image-20210313230119731](https://i.loli.net/2021/03/13/zYQ2ijIUWJ9fTXw.png)

---

**哈希索引**

利用哈希函数h，根据关键字k计算出槽的位置。InnoDB中采用除法散列函数，冲突机制采用拉链法。

![img](https://imgconvert.csdnimg.cn/aHR0cHM6Ly91c2VyLWdvbGQtY2RuLnhpdHUuaW8vMjAxOC85LzI0LzE2NjBjMGYxNThhNzZmOTQ?x-oss-process=image/format,png)

**B+树相对Hash的区别 / 优劣 / 为什么不用hashmap**⭐

在大多数情况下，直接选择B+树索引可以获得稳定且较好的查询速度，而不需要使用hash索引。

- hash索引查询不稳定。hash索引虽然在等值查询上较快，但当某个键值存在大量重复的时候，hash冲突次数多，效率差；B+树所有的查询都是从根节点到叶子节点
- hash索引不支持顺序查询。hash函数使得hash索引的顺序与原顺序无法保持一致
- hash索引不支持范围查询
- hash索引不支持模糊查询及最左匹配原则
- hash索引不支持覆盖索引，避免不了回表查询

#### 索引分类⭐

**索引有哪几种类型？**

**1 主键索引（聚簇索引、聚集索引、密集索引）**

将数据与索引存放在一起，找到索引也就找到了数据

InnoDB 表中，若没有显示指定主键，则 InnoDB 会自动检查表中是否有唯一索引的字段，如果有，则选择该字段为默认的主键；否则会自动创建一个 6Byte 的自增主键。

**2 非主键索引（稀疏索引、非聚集索引、辅助索引、二级索引）**

将数据与索引分开，叶节点只有一个指针（书签）指向对应的数据块


- 普通索引：基本的索引类型，允许为NULL值。
- 唯一索引：数据列不允许重复，允许为NULL值，一个表允许多个列创建唯一索引。建立唯一索引的目的大部分是为了该列数据的唯一性，而不是查询效率。
- 前缀索引：只适用于字符串类型的数据，对前几个字符创建索引。
- 全文索引：主要是为了检索大文本数据中的关键字信息，是目前搜索引擎使用的一种关键技术。

**何时使用聚簇索引与非聚簇索引**

<img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy8xMDE1NDQ5OS1kNTNhNWNlOWNlY2YyMmYzLnBuZw?x-oss-process=image/format,png" alt="img" style="zoom: 80%;" />

**聚集索引与非聚集索引的区别**⭐

- 聚集索引一个表只可以有一个；非聚集索引一个表可以有多个
- 聚簇索引的叶子节点就是数据节点；非聚簇索引的叶子节点只有一个指针（书签）指向对应的数据块
- 聚集索引中键值的逻辑顺序决定了表的物理顺序；非聚集索引则不是

#### 索引使用⭐

**索引设计的原则 / 创建索引的原则**⭐

- 最左前缀原则
- 不要过度索引
- 尽量扩展而不要新建索引
- 查询频繁的字段适合创建索引
- 更新频繁的字段不适合创建索引
- 区分度低的字段不适合加索引
- 越小的数据类型通常更好。越小的数据类型通常在磁盘、内存和CPU缓存中需要更少的空间，处理起来更快。
- 简单的数据类型更好。整型数据比字符的处理开销更小，因为字符的比较更复杂；应用内置的日期和时间数据类型，而不是用字符串来存储时间；用整型数据类型存储IP地址。
- 应指定列为NOT NULL，除非你想存储NULL。在mysql中，含有空值的列很难进行查询优化，因为它们使得索引、索引的统计信息以及比较运算更加复杂。你应该用0、一个特殊的值或者一个空串代替空值；

**索引哪些情况会失效**⭐ [参考](https://blog.csdn.net/qq_43332570/article/details/106901688) 

理论+实际，给出sql语句要能判断出具体的情况！

- 最左前缀原则，如对(a,b,c)
  
  - where b = XX and c = XX and a = XX **优化器优化，全部生效**，但性能会差些
  - where  d = XX and b = XX **优化器优化，b 生效**，但性能会差些
  - where b = XX and c = XX **全部失效**
- 后面失效
  - 索引列使用like通配符，没有以%开头。解决方法：覆盖索引
  - 索引列使用运算> < != not in
- 全部失效
  - 索引列进行计算、函数、自动或手动的类型转换（如字符串且在where中没有用引号括起来）
  - 索引列使用or。解决方法：要想使用or，又想让索引生效，只能将or条件中的每个列都加上索引

> 索引列使用 is null、is not null 未知

---

**百万级别或以上的数据如何删除**

删除数据库百万级别时，查询MySQL官方手册得知删除数据的速度和创建的索引数量是成正比的。

- 先删除索引（大概三分多钟）
- 然后删除其中无用数据（不到两分钟）
- 删除完成后重新创建索引（此时数据较少了创建索引也非常快，约十分钟左右）

**列值为NULL时，是否会用到索引？**

列值为NULL也是可以走索引的

在mysql中，含有空值的列很难进行查询优化，因为它们使得索引、索引的统计信息以及比较运算更加复杂。你应该用0、一个特殊的值或者一个空串代替空值；

### 锁

#### 锁分类⭐

<img src="https://pic4.zhimg.com/80/v2-ed75345f32a89121c578e313ead82d07_720w.jpg" alt="img" style="zoom: 80%;" />

**1 锁粒度** [参考](https://zhuanlan.zhihu.com/p/296545804) [参考但部分有误](https://learnku.com/articles/39212)

| 引擎   | 表锁 | 行锁 | 页   |
| ------ | ---- | ---- | ---- |
| InnoDB | 支持 | 支持 |      |
| MyISAM | 支持 |      |      |
| BDB    | 支持 |      | 支持 |

- 表锁（Table-level lock）
  
  - 特点：对整张表加锁，锁粒度大，锁冲突的概率高，并发度低；但开销小，加锁快；不会出现死锁；
  
- 行锁（Record Locks）
  - **前提条件**：索引。因为InnoDB是通过给索引的索引项加锁来实现行锁的。否则使用表锁

  - 特点：对一行数据加锁，锁粒度小，锁冲突概率低，并发性高；但开销大，加锁慢；会出现死锁；

    > 行锁有死锁的危险。由于InnoDB的索引机制，数据库操作使用主键索引时，InnoDB会锁住主键索引；使用非主键索引时，InnoDB会先锁住非主键索引，再锁定主键索引。[参考](https://zhuanlan.zhihu.com/p/66676020)

- 页锁
  - 页级锁主要应用于 BDB 存储引擎。
  - 特点：锁定粒度介于表锁和行锁之间，并发度一般；开销和加锁速度介于表锁和行锁之间；会出现死锁；

---

**2 行锁算法** [参考](https://zhuanlan.zhihu.com/p/66676020)

<img src="https://pic3.zhimg.com/80/v2-5e4ba1788cf2ce3d583cae13a18d27e6_720w.jpg" alt="img" style="zoom:80%;" />

- Record Lock （记录锁）：锁住索引记录，如果没有设置索引，InnoDB会使用隐式的主键进行锁定
- Gap Lock （间隙锁）：锁定一个范围，但不包含记录本身。
  - 针对的隔离级别为可重复读或以上。
  - InnoDB中唯一作用是Next-Key Lock来解决幻读问题
- Next-key Lock （临建锁）：锁定一个范围，并且包含记录本身（左开右闭），行锁+间隙锁。
  - InnoDB使用Next-Key Lock来解决幻读问题。
  - 当查询的索引为主键索引或唯一索引时，Next-Key Lock 会降级为 Record Lock。
  - 当查询的索引为辅助索引时，使用Next-Key Lock锁住辅助索引值所在的范围，还会将其下一键值加上Gap LOCK。

---

**3 实现机制**

<img src="https://cdn.learnku.com/uploads/images/202001/05/32495/ZEw4DFkZI2.png!large" alt="一张图彻底搞懂 MySQL 的锁机制" style="zoom: 33%;" />

- 悲观锁：如行锁，表锁；读锁，写锁等

- 乐观锁：适用于读多写少的应用场景，提高吞吐量。实现方式

  - 数据版本（Version）：为数据增加一个数字类型的版本标识。每次比较此字段……（个人觉得类似CAS）

    > MySQL的MVCC的实现就是此种方式

  - 时间戳（timestamp）：和数据版本类似，增加一个时间戳类型的字段。


---

**4 兼容性**

<img src="https://pic4.zhimg.com/80/v2-37761612ead11ddc3762a4c20ddab3f3_720w.jpg" alt="img" style="zoom: 67%;" />

- 共享锁S：又称读锁 (read lock)。多个读操作可以同时进行，但会阻塞其他写操作。

- 排他锁X：又称写锁(writer lock)。会阻塞其它事务的读写操作。（只能当前事务进行读写）

- **意向锁：都是表锁，不会与行级的共享 / 排他锁互斥！！！**

  - 分类

    - 意向共享锁IS：事务在给一个数据行加S锁前必须先取得该表的IS锁。
    - 意向排他锁IX：事务在给一个数据行加X锁前必须先取得该表的IX锁。

  - 存在的意义 ：一个事务尝试获得**表**的共享或排他锁时，只需检查表上的意向锁不必一行一行检查行锁，提高效率

    例子：A加一行X锁，B尝试加表级S锁时，会发现表级S锁与A的表级IX锁互斥，故加锁失败。这样就不用去一行行看有没有行级互斥锁了。[参考](https://juejin.cn/post/6844903666332368909#heading-1)

**上锁方式**

- 普通SELECT语句，InnoDB不会加任何锁，可以通过以下语句显示加锁
  - 共享锁S：SELECT * FROM table_name WHERE ... **LOCK IN SHARE MODE**。用于需要数据依存关系时来确认某行记录是否存在， 并确保没有人对记录进行UPDATE或者DELETE操作。但如果当前事务也需要对该记录进行更新操作，则很有可能造成死锁
  - 排他锁X：SELECT * FROM table_name WHERE ... **FOR UPDATE**。用于锁定行记录后需要进行更新操作的应用
- UPDATE、DELETE和INSERT写操作，InnoDB会自动给涉及数据集加排他锁X；
- 意向锁是InnoDB自动加的，不需用户干预。

#### MVCC⭐

**为什么上了写锁，别的事务还可以读操作？** 

InnoDB有MVCC机制（多版本并发控制），可以使用快照读，而不会被阻塞。

**MVCC原理**⭐ [参考](https://mp.weixin.qq.com/s/yWpFX-OUXlfZpiDz4GjVUw)

MVCC（多版本并发控制）：MySQL中基于乐观锁实现隔离级别的方式。通过读取历史版本数据，降低并发事务冲突，从而提高并发性能

- 隐藏列：每行数据都有隐藏列，包含本行数据的事务id、指向undo log的指针等。
- 基于undo log的版本链：每条undo log也会指向更早版本的undo log，从而形成一条版本链。

- ReadView：主要将当前系统中活跃的读写事务id放到一个列表中，名为m_ids。
  - 被访问版本的 trx_id 小于 m_ids 中最小事务id（低水位），说明生成该版本的事务在生成 ReadView 前已提交 **可见**
  - 被访问版本的 trx_id 大于 m_ids 中最大事务id（高水位），说明生成该版本的事务在生成 ReadView 后才生成 不可见
  - 被访问版本的 trx_id 在 m_ids 中最大事务id和最小事务id之间，则继续判断 trx_id 属性值是否在 m_ids 中。如果在，说明该版本的事务活跃，该版本对当前事务不可见；如果不在，说明该版本的事务已经被提交 **可见**

#### 数据库死锁⭐

**什么是死锁？**

死锁是指多个进程因竞争资源而造成的一种僵持状态。若无外力作用，这些进程都将永远处于阻塞状态，不能再运行下去。                

（死锁是指两个或多个事务在同一资源上相互占用，并请求锁定对方的资源，从而导致恶性循环的现象。）

**常见的解决死锁的方法**

- **加锁顺序一致**，尽可能一次性锁定所需的数据行
- 单次操作数据量不宜过多，涉及表尽量少
- 精心设计索引，**尽量使用索引访问数据**
- 减少表上索引，减少锁定资源
- 尽量基于primary（主键）或unique key更新数据
- 尽量使用较低的隔离级别
- 尽量使用相同条件访问数据，避免间隙锁对并发的插入影响
### 事务

#### ACID⭐

**什么是事务？**

事务是一个原子操作：要么全部被执行，要么全部都不执行。

事务在执行的过程中，不会被其他客户端发送来的命令请求所打断。

**ACID是什么**

- 原子性： 事务是最小的执行单位，要么全成功，要么全失败。
- 一致性： 执行事务前后数据保持一致，多个事务对同一个数据读取的结果相同；
- 隔离性：不同事务之间互不影响，四种隔离级别RU（读未提交）、RC（读已提交）、RR（可重复读）、SERIALIZABLE （串行化）
- 持久性： 事务提交后，对数据的修改是永久性的，即使系统故障也不会丢失。

**如何实现事务ACID特性 / 事务是如何通过日志来实现的** [参考](https://www.cnblogs.com/kismetv/p/10331633.html)

- 原子性：undo log。事务执行中出错或执行rollback时，通过undo log日志回滚。
- 一致性
  - 保证原子性、隔离性、持久性
  - 数据库本身提供保障，如不允许向整形列插入字符串值、字符串长度不能超过列的限制等
  - 应用层面进行保障，如转账操作只扣除转账者的余额，而没有增加接收者的余额，则也无法保证状态的一致
- 隔离性：四大隔离级别原理各不相同……
- 持久性：redo log。系统崩溃时可通过redo log恢复数据（两阶段提交）。

#### 隔离级别⭐

**什么是脏读？幻读？不可重复读？**

- 脏读(Drity Read)：当前事务可以读到其他事务**未提交的数据**（脏数据）
- 不可重复读(Non-repeatable read)：事务**两次读同一个数据，数据不同**。脏读与不可重复读的区别在于：前者读到的是其他事务未提交的数据，后者读到的是其他事务已提交的数据。
- 幻读(Phantom Read)：事务**两次读同一数据，条数不同**。不可重复读与幻读的区别可以通俗的理解为：前者是数据变了，后者是数据的行数变了。

**什么是事务的隔离级别？MySQL的默认隔离级别是什么？**

<img src="https://img2018.cnblogs.com/blog/1174710/201901/1174710-20190128201034603-681355962.png" alt="img" style="zoom:80%;" />

- READ-UNCOMMITTED(读未提交)：允许读另一事务尚未提交的数据。
- READ-COMMITTED(读已提交)： 允许读另一事已提交的数据。
- **REPEATABLE-READ(可重复读RR)**： 默认，同一数据多次读取的结果一致。
- SERIALIZABLE(可串行化)： 完全服从ACID。所有的事务依次逐个执行，不可能产生干扰。

**隔离级别实现原理** [参考](https://www.jianshu.com/p/dab1c0ecbac0)

**1 读未提交**

只用写锁使得不同事务写写互斥（无读锁）

**2 读已提交**

MVCC：每次查询都会生成一个新的 ReadView

**3 可重复读**⭐ 

MVCC：第一次查询时生成的 ReadView会一直沿用到事务提交。

**mysql默认隔离级别能解决幻读吗** [参考](https://blog.csdn.net/qq_42914528/article/details/103790555)

不能彻底解决。MVCC对于幻读的解决并不彻底，只解决了读情况下的幻读问题，而**写操作依旧存在幻读问题**。

原因

- select读操作是**快照读**的模式，会记录下这次select的结果，之后select 返回的也是这次快照的数据。此时其他事务提交的数据无影响
- update、insert、delete写操作是**当前读**的模式，会记录最新的结果。此时其他事务提交的数据有影响

解决方法

- MVCC+next-key locks
- 使用可串行化读的隔离级别

**4 可串行化**

完全使用读锁和写锁保证数据一致性。

### 备份与恢复

#### 主从复制

**MySQL主从复制解决的问题 / 主从复制的作用**

将主数据库中的DDL和DML操作通过二进制日志（BINLOG）传输到从数据库上，然后将这些日志重新执行（重做）；从而使得从数据库的数据与主数据库保持一致。

- 数据分布：在不同位置分布数据备份
- 负载均衡：降低单个服务器的压力
- 高可用和故障切换：帮助应用程序避免单点失败
- 升级测试：可以用更高版本的MySQL作为从库

**复制过程**

- master在每个事务更新完成之前，将该操作记录串行写入binlog文件中。
- salve开启一个I/O Thread，读取binlog并写入到中继日志。如果读取进度跟上master，则进入睡眠状态并等待master产生新的事件
- SQL Thread读取中继日志并顺序执行日志中的SQL事件

<img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91c2VyLWdvbGQtY2RuLnhpdHUuaW8vMjAxOC85LzIxLzE2NWZiNjgzMjIyMDViMmU?x-oss-process=image/format,png" alt="img" style="zoom: 50%;" />

**主从同步延迟的原因**

- 一个服务器与客户端有多个连接，会导致大量的更新操作，但从服务器读取binlog的线程仅有一个。
- 当某个SQL在从服务器上执行的时间稍长或锁表就会导致主服务器的SQL大量积压，未被同步到从服务器，导致主从延迟。

**主从同步延迟的解决办法**

- 降低对从服务器的安全要求

  > 因为主服务器要负责更新操作，他对安全性的要求比从服务器高，有 sync_binlog=1，innodb_flush_log_at_trx_commit = 1 之类的设置，而slave则不需要这么高的数据安全，完全可以讲sync_binlog设置为0或关闭binlog，innodb_flushlog，innodb_flush_log_at_trx_commit也 可以设置为0来提高sql的执行效率，这个能很大程度上提高效率。

- 使用比主库更好的硬件设备作为slave。

- 把一台从服务器作为备库，而不提供查询功能，减轻从服务器负载，提高 relay log 里SQL的效率

- 增加从服务器，分散读的压力，从而降低服务器负载。

**你是否做过主从一致性校验，如果有，怎么做的，如果没有，你打算怎么做？**

主从一致性校验有多种工具 例如checksum、mysqldiff、pt-table-checksum等

#### 恢复

**数据表损坏的修复方式有哪些？**

使用 myisamchk 修复

- 修复前将mysql服务停止。
- 打开命令行方式，然后进入到mysql的/bin目录。
- 执行myisamchk –recover 数据库所在路径/*.MYI

### 优化

#### 优化慢查询⭐

**关心过业务系统里面的sql耗时吗？统计过慢查询吗？对慢查询都怎么优化过？**

- 通过慢查询日志定位那些执行效率较低的 sql 语句
- explain 分析低效 sql 的执行计划
- 确定问题并采取相应的措施

  - 索引（创建索引的原则……避免索引失效……）
  - 读写分离
  - 分库分表
  - 减少连表，使用子查询

**慢查询日志** 

用于记录执行时间超过设置的临界时间的SQL日志，快速定位慢查询，为优化做参考。

- 查看日志位置，超时时间等设置  `show variables like '%slow%`

- 开启慢查询日志 [参考](https://blog.csdn.net/zmzwll1314/article/details/114811804)

- 设置临界时间 `set long_query_time=0.5`


![img](https://img-blog.csdn.net/20181019133806180?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ZhbmdrYW5nNw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

---

**执行计划⭐**

**怎么看执行计划（explain），如何理解其中各个字段的含义。** [参考](https://blog.csdn.net/wuseyukui/article/details/71512793?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.control&dist_request_id=&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.control)

执行计划是显示存储引擎对于SQL语句的执行的详细情况，其中包含了是否使用索引，使用什么索引，索引的相关信息等。

<img src="https://img-blog.csdnimg.cn/20200310171131582.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1RoaW5rV29u,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" style="zoom:80%;" />

**1 id**

表示一个查询中各个子查询的执行顺序;

- id相同，执行顺序由上至下。
- id不同，id值越大优先级越高，越先被执行。
- id为null时表示一个结果集，不需要使用它查询，常出现在包含union等查询语句中。

**2 select_type**

每个子查询的查询类型

| id   | select_type  | description                               |
| ---- | ------------ | ----------------------------------------- |
| 1    | SIMPLE       | 不包含任何子查询或union等查询             |
| 2    | PRIMARY      | 包含子查询最外层查询就显示为 PRIMARY      |
| 3    | SUBQUERY     | 在select或 where字句中包含的查询          |
| 4    | DERIVED      | from字句中包含的查询                      |
| 5    | UNION        | 出现在union后的查询语句中                 |
| 6    | UNION RESULT | 从UNION中获取结果集，例如上文的第三个例子 |

**3 table**

查询的数据表

**4 type**⭐

访问类型，**可以看有没有走索引**

> 【推荐】SQL性能优化的目标：至少要达到 range 级别，要求是ref级别，如果可以是consts最好。 

- **ALL** 扫描全表数据
- **index** 全索引扫描，通常出现在覆盖索引
- **range** 索引范围查找
- **ref** 使用非唯一索引
- eq_ref 在join查询中使用PRIMARY KEYorUNIQUE NOT NULL索引关联。
- **const** 针对主键或唯一索引的等值查询扫描，最多只返回一行数据。const 查询速度非常快, 因为它仅仅读取一次即可.
- system  表中只有一条数据，是特殊的 `const` 类型。
- NULL MySQL在优化过程中分解语句，执行时甚至不用访问表或索引，例如从一个索引列里选取最小值可以通过单独索引查找完成。

**5 possible_keys**⭐

可能使用的索引，注意不一定会使用。当该列为 NULL时就要考虑当前的SQL是否需要优化了。

**6 key**⭐ 

显示查询中实际使用的索引。必然包含在possible_keys中

**7 key_length** 

表示索引中使用的字节数，可通过该列计算查询中使用的索引的长度。不损失精确性的情况下，长度越短越好 

**8 ref** 

列与索引的比较，表示上述表的连接匹配条件，即哪些列或常量被用于查找索引列上的值

**9 rows** 

返回估算的结果集数目，并不是一个准确的值。

**10 extra**⭐ 

执行情况的描述和说明

- Using index 使用覆盖索引
- Using where 使用了where子句来过滤结果集
- Using filesort 使用文件排序，非索引列排序时出现，非常消耗性能，尽量优化。
- Using temporary 使用了临时表，常见于order by 和 group by

#### 优化LIMIT分页⭐

**limit 1000000加载很慢的话，你是怎么解决的呢？**

- 利用**延迟关联或者子查询**优化超多分页场景。（先快速定位需要获取的id段，然后再关联）

  SELECT a.* FROM employee a, (select id from employee where 条件 LIMIT 1000000,10 ) b where a.id=b.id

  > 阿里巴巴《Java开发手册》中
  >
  > **【推荐】利用延迟关联或者子查询优化超多分页场景。 
  >
  > 说明：MySQL并不是跳过offset行，而是取offset+N行，然后返回放弃前offset行，返回N行，那当offset特别大的时候，效率就非常的低下，要么控制返回的总页数，要么对超过特定阈值的页数进行SQL改写。 
  >
  > 正例：先快速定位需要获取的id段，然后再关联： 
  >
  > SELECT a.* FROM 表1 a, (select id from 表1 where 条件 LIMIT 100000,20 ) b where a.id=b.id**

- 如果id是连续的，可以这样，返回上次查询的最大记录(偏移量)，再往下limit

  select id，name from employee where id>1000000 limit 10.

- order by + 索引（id为索引）

  select id，name from employee order by id limit 1000000，10

- 使用缓存，可预测性的提前查到内容，缓存至redis等k-V数据库中

- 在业务允许的情况下限制页数：

  建议跟业务讨论，有没有必要查这么后的分页啦。因为绝大多数用户都不会往后翻太多页

**一个6亿的表a，一个3亿的表b，通过外键tid关联，你如何最快的查询出满足条件的第50000到第50200中的这200条数据记录。**

1、如果A表TID是自增长,并且是连续的,B表的ID为索引

select * from a,b where a.tid = b.id and a.tid>500000 limit 200;

2、如果A表的TID不是连续的,那么就需要使用覆盖索引.TID要么是主键,要么是辅助索引,B表ID也需要有索引。

select * from b , (select tid from a limit 50000,200) a where b.id = a .tid;

#### 大表优化⭐

**大表怎么优化？某个表有近千万数据，CRUD比较慢，如何优化？分库分表了是怎么做的？** [参考](https://www.jianshu.com/p/92f96640cf72) [参考](https://www.cnblogs.com/aksir/p/9085694.html)

- 优化索引
- 读写分离：主库负责写，从库负责读；
- 分库分表：垂直（纵向）切分、水平（横向）切分。
- 限定数据的范围： 禁止不带任何限制范围的查询语句。比如：我们当用户在查询订单历史的时候，我们可以控制在一个月的范围内
- 缓存：对重量级、更新少的数据可以考虑使用应用级别的缓存；

**分库分表分别解决了什么问题？** [参考](https://www.zhihu.com/question/448775613/answer/1774351830)

- 分库：连接数限制（IO）；高可用
- 分表：表大小限制（CPU、内存、磁盘）

---

**1 垂直切分**

**垂直分库**

基于**业务**分类，每一个独立的服务都拥有自己的数据库，不同业务的数据需接口调用。

<img src="https:////upload-images.jianshu.io/upload_images/19895418-d6f0ced8ef1e774e?imageMogr2/auto-orient/strip|imageView2/2/w/386/format/webp" alt="img" style="zoom: 80%;" />

**垂直分表**

基于数据表的列切分，是一种大表拆小表的模式。

例如：一个`order`表有很多字段，把长度较大且访问不频繁的字段，拆分出来创建一个单独的扩展表`work_extend`进行存储。

<img src="https://camo.githubusercontent.com/9aa9bdea42aac1c9285dc568a98535591f38a9410dfee5f8ab9ab9523d170004/68747470733a2f2f6d792d626c6f672d746f2d7573652e6f73732d636e2d6265696a696e672e616c6979756e63732e636f6d2f323031392d362f2545362539352542302545362538442541452545352542412539332545352539452538322545372539422542342545352538382538362545352538432542412e706e67" alt="数据库垂直分区" style="zoom:67%;" />

> **优点**
>
> - 业务间解耦，不同业务的数据进行独立的维护、监控、扩展
> - 在高并发场景下，一定程度上缓解了数据库的压力
>
> **缺点**
>
> - 提升了开发的复杂度，由于业务的隔离性，很多表无法直接访问，必须通过接口方式聚合数据，
> - 分布式事务管理难度增加
> - 数据库还是存在单表数据量过大的问题，并未根本上解决，需要配合水平切分
>

---

**2 水平切分**

**水平分表**

水平切分将一张大数据量的表，切分成多个表结构相同，而每个表只占原表一部分数据，然后按不同的条件分散到多个数据库中。

假如一张`order`表有2000万数据，水平切分后出来四个表，`order_1`、`order_2`、`order_3`、`order_4`，每张表数据500万，以此类推。

<img src="https://camo.githubusercontent.com/37edf99bfacbc5479884b99974b35ea3717e04940540c100a9040748af20563b/68747470733a2f2f6d792d626c6f672d746f2d7573652e6f73732d636e2d6265696a696e672e616c6979756e63732e636f6d2f323031392d362f2545362539352542302545362538442541452545352542412539332545362542302542342545352542392542332545362538422538362545352538382538362e706e67" alt="数据库水平拆分" style="zoom:80%;" />

库内分表虽然将表拆分，但子表都还是在同一个数据库实例中，只是解决了单一表数据量过大的问题，并没有将拆分后的表分布到不同机器的库上，还在竞争同一个物理机的CPU、内存、网络IO。

<img src="https:////upload-images.jianshu.io/upload_images/19895418-afa4045099379109?imageMogr2/auto-orient/strip|imageView2/2/w/683/format/webp" alt="img" style="zoom:67%;" />

**水平分库**

将切分出来的子表分散到不同的数据库中，达到分布式的效果。

水平分库分表切分规则

- RANGE：从0到10000一个表，10001到20000一个表；
- HASH取模：一个商场系统，一般都是将用户，订单作为主表，然后将和它们相关的作为附表，这样不会造成跨库事务之类的问题。 取**用户id**，然后hash取模，分配到不同的数据库上。
- 地理区域：比如按照华东，华南，华北这样来区分业务，七牛云应该就是如此。
- 时间：按照时间切分，就是将6个月前，甚至一年前的数据切出去放到另外的一张表，因为随着时间流逝，这些表的数据 被查询的概率变小，所以没必要和“热数据”放在一起，这个也是“冷热数据分离”。

> **优点**
>
> - 解决高并发时单库数据量过大的问题，提升系统稳定性和负载能力
> - 业务系统改造的工作量不是很大
>
> **缺点**
>
> - 跨分片的事务一致性难以保证
> - 跨库的join关联查询性能较差
> - 子表数多时扩容的难度和维护量较大
>

---

**分库分表后面临的问题**

**1 ID问题**⭐ [参考](https://zhuanlan.zhihu.com/p/107420326)

分库分表后需要有一个全局唯一ID来标识一条数据，即分布式ID。数据库的自增ID显然不能满足需求

**解决方案**

- 基于UUID：UUID有着全球唯一的特性。但不具备趋势自增特性，主键过长

- 基于Mysql自增ID：需要一个ID的时候，向表中插入一条记录返回主键ID。但访问量激增时MySQL本身就是系统的瓶颈

- 基于Mysql集群：多个数据库分步生成ID。但难以扩容

- 基于Mysql号段：从数据库选出一个号段范围批量获取自增ID。采用版本号version乐观锁方式更新

- 基于Redis：利用redis的incr命令实现ID的原子性自增。需考虑redis持久化的问题

- 基于雪花算法(Snowflake)：Long类型的ID，占8个字节

  ![img](https://pic4.zhimg.com/80/v2-db168d8c5600654f38c6df3802450e1f_720w.jpg)

  - 符号位（1bit）：代表正负，正数是0，负数是1，一般生成ID都为正数，所以默认为0。
  - 时间戳部分（41bit）：毫秒级的时间，不建议存当前时间戳，而是用（当前时间戳 - 固定开始时间戳）的差值，可以使产生的ID从更小的值开始；41位的时间戳可以使用69年，(1L << 41) / (1000L * 60 * 60 * 24 * 365) = 69年
  - 工作机器id（10bit）：可以灵活配置，机房或者机器号组合都可以。
  - 序列号部分（12bit）：支持同一毫秒内同一个节点可以生成4096个ID

**数据库自增主键可能遇到什么问题？**

- 自增主键可能用完
- 自增主键会产生表锁
- 分库分表时可能出现诸如主键重复等的问题

**2 事务支持**⭐

分库分表后就成了分布式事务了。如果依赖数据库本身的分布式事务管理功能去执行事务，将付出高昂的性能代价； 如果由应用程序去形成程序逻辑上的事务，又会造成编程方面的负担。

解决方案：最终一致性方案。不苛求系统的实时一致性，只要在允许的时间段内达到最终一致性即可，可采用事务补偿的方式

**3 跨库join**⭐

只要是进行切分，跨节点Join的问题是不可避免的。

解决方案：普遍做法是分两次查询实现。在第一次查询的结果集中找出关联数据的id，根据这些id发起第二次请求得到关联数据。 

**4 跨节点的count,order by,group by以及聚合函数问题**

都需要基于全部数据集合进行计算。

解决方案：与解决跨节点join类似，在各个节点上得到结果后在程序端进行合并，不同的是每个结点的查询可以并行执行，

**5 跨分片的排序分页**

当排序字段非分片字段的时候，情况就会变得比较复杂了。

解决方案：在不同的分片节点中将数据进行排序并返回，并将不同分片返回的结果集进行汇总和再次排序，最后再返回给用户。

<img src="https://img-blog.csdnimg.cn/20200310170753848.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1RoaW5rV29u,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" style="zoom: 67%;" />

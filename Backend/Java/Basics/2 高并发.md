### 概述 1 

#### 并发编程优缺点

多线程是指程序中包含多个执行流，同时执行多个不同的任务。

**为什么要使用并发编程（并发编程的优点）**

- 充分利用多核CPU的计算能力，提升系统性能和并发能力
- 方便进行业务拆分：面对复杂业务模型，并行程序会比串行程序更适应业务需求。

**并发编程缺点及解决**

- **上下文切换**：任务从保存到再加载的过程就是一次上下文切换，非常损耗性能
- 使用最少线程：避免创建不必要的线程（比如任务很少，但创建了很多线程，这会造成大部分线程都处于等待状态）
  - 无锁并发编程：参照ConcurrentHashMap锁分段的思想，不同线程处理不同段的数据
- CAS：使用乐观锁，可以有效减少一部分不必要的锁竞争带来的上下文切换
  - 协程：在单线程中实现多任务的调度，并在单线程中维持多个任务间的切换

- **线程安全**：最难以把握的就是临界区线程安全问题，一旦产生死锁就会造成系统功能不可用。
- 避免一个线程持有多个锁
  - 避免一个线程在锁内部占用多个资源，尽量一个锁占用一个资源
- 尝试使用定时锁，使用`lock.tryLock(timeOut)`，当超时等待时当前线程不会阻塞
  - 数据库锁加锁和解锁必须在同一个连接里，否则会出现解锁失败的情况

- 占用内存：线程也是程序，所以线程需要占用内存，线程越多占用内存也越多；

- 降低稳定性：JVM在可创建线程的数量上存在一个限制，破坏则可能抛出 OutOfMemoryError 异常



#### 并发编程三要素⭐

- **原子性**：原子操作指不可被中断的操作
- synchronized：加锁
  - 基本数据类型都具备原子性，但虚拟机将没有被 volatile 修饰的 64 位数据（long 和 double）划分为两次 32 位操作。

- **可见性**：一个线程对共享变量的修改，另一个线程能够立刻看到
  - volatile：保证新值能立即同步到主内存，每次使用前立即从主内存刷新。
  - synchronized：对一个变量执行 **解锁前必须先把此变量同步回主内存**，即先执行 store 和 write。
  - final：**构造方法中**初始化完成，并且没有把 this 引用传递出去时，其他线程能看到 final 字段的值。

- **有序性**：程序执行的顺序按照代码的先后顺序执行
  - volatile：内存屏障
  - synchronized：保证一个变量在同一时刻只允许一个线程对其进行 lock 操作
  - final：内存屏障

**在 Java 程序中为什么会有并发编程问题？** [参考](https://www.it610.com/article/1296030232725233664.htm)

- 线程切换带来的原子性问题
- 缓存导致的可见性问题
- 编译优化带来的有序性问题

**并发问题解决**

- 使用自动锁 synchronized……
- 使用手动锁 Lock(AQS)
- 使用安全类如原子类(CAS)

**高并发架构**

juc包架构图：《艺术》中4-10章

<img src="C:/Users/lxr/AppData/Roaming/Typora/typora-user-images/image-20210305102257829.png" alt="image-20210305102257829" style="zoom:200%;" />

concurrent包的实现

<img src="https://i.loli.net/2021/02/01/OUI1bPrcBeZ3Hud.png" alt="image-20210201111112150" style="zoom:67%;" />

#### CAS⭐

**什么是 CAS** [参考](https://blog.csdn.net/liangwenmail/article/details/80832580) [参考](https://yq.aliyun.com/articles/626910)

CAS 是 compare and swap 的缩写，即比较交换，是一种基于乐观锁的原子操作。

包含三个操作数：内存位置V、预期原值A和新值B。

- 先从内存位置中读取预期原值
- 运行程序得新值
- 若当前内存位置的值和预期原值相同，则将内存位置的值更新为新值。反之则重新返回第一步，一直自旋

底层：CAS是一条CPU并发原语，CAS指令在Intel CPU上称为CMPXCHG指令，**硬件命令**保证了CAS的原子性且速度快。

**CAS 会产生什么问题？如何解决？**⭐

- ABA 问题
  - 比如说一个线程 one 从内存位置 V 中取出 A，这时候另一个线程 two 也从内存中取出 A，并且 two 进行了一些操作变成了 B，然后 two 又将 V 位置的数据变成 A，这时候线程 one 进行 CAS 操作发现内存中仍然是 A，然后 one 操作成功，但可能存在潜藏的问题（如资金挪用）
  - 从 Java1.5 开始 JDK 的 atomic包里提供了一个类 AtomicStampedReference 来解决 ABA 问题。这个类的compareAndSet方法作用是首先检查**当前引用和标志是否等于预期**，全部相等才更新。


- 循环时间长时开销大

  - 对于线程冲突严重的情况，CAS 自旋的概率会比较大，从而浪费更多的 CPU 资源，效率低。
  - JVM支持处理器提供的pause指令

    - 延迟流水线执行指令
    - 避免退出循环时因内存顺序冲突而引起的CPU流水线被清空


- 只能保证一个共享变量的原子操作

  - 对多个共享变量操作时，CAS 就无法保证操作的原子性。
  - 三种方法

    - 用锁
    - 把多个共享变量合并成一个共享变量来操作。如读写锁的AQS状态变量
    - 把多个变量放在一个对象里进行CAS操作。从Java1.5开始JDK提供的AtomicReference类

**乐观锁和悲观锁的理解**

悲观锁：总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以**将资源锁住**，锁释放后才能访问

乐观锁：每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会**判断有无他人更新数据**。乐观锁适用于多读的应用类型，提高吞吐量。

**乐观锁的实现方式**

- 时间戳
- 版本标识
- CAS ……

### JMM 2 3

#### JMM内存模型⭐

<img src="https://img-blog.csdn.net/20181009230945499?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L21hX2NoZW5fcXE=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="在这里插入图片描述" style="zoom:67%;" />

- 所有变量都存储在主内存，每个线程有自己的工作内存（本地内存），工作内存中保存主内存的副本。线程对变量的所有操作都必须在工作内存进行，不能直接读写主内存。
- Java 线程通信由 JMM 控制，JMM 定义了变量的访问规则，但不包括局部变量、方法参数等线程私有的值。
- JMM 基本原则：只要不改变程序执行结果，编译器和处理器怎么优化都行。例如优化后某个锁只会单线程访问就消除锁，某个 volatile 变量只有单线程访问就当作普通变量。
- 关于主内存与工作内存的交互，JMM 定义了 **8 种原子操作**：

| 操作   | 作用范围 | 作用                         |
| ------ | -------- | ---------------------------- |
| lock   | 主内存   | 把变量标识为锁定状态         |
| unlock | 主内存   | 释放锁定状态的变量           |
| read   | 主内存   | 把变量值从主内存读到工作内存 |
| load   | 工作内存 | 把 read 值加载到工作内存     |
| use    | 工作内存 | 把 load 值传给执行引擎       |
| assign | 工作内存 | 把 use 值赋给工作内存变量    |
| store  | 工作内存 | 把 assign 值传到主内存       |
| write  | 主内存   | 把 store 值写回主内存变量    |

#### 重排序

![在这里插入图片描述](https://img-blog.csdn.net/20181009231337835?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L21hX2NoZW5fcXE=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

**什么是重排序？**

- 执行任务的时候，为了提高执行性能，编译器和处理器会对指令重排序。

- 编译器优化重排序是编译器重排序，指令重排序和内存重排序是处理器重排序
  - 编译器重排序：在不改变单线程语义的情况下重新安排语句的执行顺序
  - 指令重排序：处理器指令级并行技术将多条指令重叠执行
  - 内存重排序：处理器使用了读写缓存区，使得加载和存储操作看起来可能乱序执行

- 重排序不会影响单线程语义，但是会**破坏多线程的语义**，导致线程安全问题（如DCL问题）。编译器重排序规禁止一些特定类型的编译器重排序，并在生成指令序列时会插入**内存屏障**来禁止某些处理器重排序。

**重排序需要满足两个条件**

- 在单线程环境下不能改变程序运行的结果；
- 存在数据依赖关系的不允许重排序

**内存屏障**

内存屏障是一个CPU指令，可以保证特定操作的执行顺序。内存屏障是硬件层的概念，不同的硬件平台实现内存屏障的手段并不一样，java通过屏蔽这些差异，统一由jvm来生成内存屏障的指令。

Load相当于是读屏障，Store相当于是写屏障。前面必须在后面之前完成或可见

![img](https://pics4.baidu.com/feed/267f9e2f070828380695c2ac89ae0d074d08f1af.jpeg?token=72266e04dd5a8a1ca873a511a6a6a6b2)

#### happens-before

**As-If-Serial语义**

单线程内程序的执行结果不能被改变。编译器、处理器进行指令重排序都必须要遵守as-if-serial语义规则。

编译器和处理器对存在依赖关系的操作，都不会对其进行重排序。但是对不存在依赖关系的操作，就有可能进行重排序。

**Happens-Before原则**

JMM通过happens-before原则向程序员提供多线程的内存可见性保证。

重排序需要遵守happens-before规则。happens-before并不是说前一个操作必须要在后一个操作之前执行，而是指前一个操作的执行结果必须对后一个操作可见：如果前一个操作必须要对后一个操作可见（A happens-before C） ，那么这两个操作指令不能重排。

**as-if-serial规则和happens-before规则的区别**

- 目的都是为了在不改变程序执行结果的前提下，尽可能地提高程序执行的并行度。
- as-if-serial语义保证**单线程**程序的执行结果不被改变；happens-before关系保证正确同步的**多线程**程序的执行结果不被改变。
- as-if-serial语义给程序员创造了一个幻境：单线程程序是按程序的顺序来执行的；happens-before关系给程序员创造了一个幻境：正确同步的多线程程序是按happens-before的顺序来执行的。

### 三个关键字 2 3

#### volatile⭐

**用法**

一写多读，只有单一的线程修改变量值，结果对其他线程立即可见，读可不用再加锁。如concurrentHashMap

---

**volatile的原理 / 特性 / 内存语义**⭐

**1 可见性**  [参考](https://blog.csdn.net/qq_33522040/article/details/95319946)

JMM……volatile修饰的变量在进行写操作时会多出一行Lock前缀指令，会引发两件事：

- 将当前处理器缓存行的数据写回到系统内存
- 使其他处理器缓存该内存地址的数据失效

**2 有序性**

前面说到的Lock前缀指令不是内存屏障却能完成类似内存屏障的功能，禁止指令重排序。

JMM采取基于保守策略的内存屏障插入策略：

- 在每个volatile写操作的前面插入一个StoreStore屏障
- 在每个volatile写操作的后面插入一个SotreLoad屏障
- 在每个volatile读操作的前面插入一个LoadLoad屏障
- 在每个volatile读操作的后面插入一个LoadStore屏障

![volatile重排序规则表](https://img-blog.csdnimg.cn/20201201212408226.png#pic_center)

**lock指令的几个作用**

- 将当前处理器缓存行的数据写回到系统内存，使其他处理器缓存该内存地址的数据失效
- 不是内存屏障却能完成类似内存屏障的功能
- 锁总线：其它CPU对内存的读写请求都会被阻塞，直到锁释放；但是锁总线的开销比较大，锁总线期间其他CPU没法访问内存，所以后面处理器都采用锁缓存替代锁总线。

---

**volatile 能使得一个非原子操作变成原子操作吗？为什么？**⭐[参考](https://blog.csdn.net/xdzhouxin/article/details/81236356?utm_medium=distribute.pc_relevant_bbs_down.none-task--2~all~sobaiduend~default-1.nonecase&depth_1-utm_source=distribute.pc_relevant_bbs_down.none-task--2~all~sobaiduend~default-1.nonecase)

不一定，volatile只能保证可见性不能完全保证原子性。

- 反例：i++并不是一个原子性操作，分为线程读取i、temp = i + 1、i = temp三步，例子：
  - 当 i=5 的时候A B两个线程同时读入了 i 的值， 都执行了 temp = i + 1的操作 
  - 然后A线程执行了 i = temp(6)的操作，volatile会使此时i的值立即刷新到主存并通知其他线程保存的 i 值失效。此时B线程重新读取 i 的值为6
  - 然后B线程执行 i=temp(6)，所以导致了i仍为6，计算结果比预期少了1
- 正例：用volatile修饰long和double可以保证操作原子性

  对于64位的long和double，如果没有被volatile修饰，其操作可以不是原子的。在操作的时候，会分成两步，每次对32位操作。但如果使用volatile修饰long和double，那么其读写都是原子操作

#### synchronized⭐

**用法**

用来控制线程同步，同步代码段不被多个线程同时执行。

- 修饰实例方法: 作用于当前对象实例加锁，进入同步代码前要获得当前对象实例的锁

- 修饰静态方法: 也就是给当前类加锁，会作用于类的所有对象实例，因为静态成员不属于任何一个实例对象，是类成员。synchronized 关键字加到 static 静态方法和 synchronized(class)代码块上都是是给 Class 类上锁。

- 修饰代码块: 指定对象加锁，进入同步代码块前要获得给定对象的锁。尽量不要 synchronized(String a)，因为JVM中字符串常量池具有缓存功能。

使用案例：单例模式

---

**synchronized的原理**⭐ [参考](https://www.jianshu.com/p/5c4f441bf142)

**非公平 可重入 悲观锁**

通过**反汇编**可知：同步方法和同步代码块底层都是通过monitor来实现同步的，每个对象都与一个monitor相关联。

- 同步方法
  - **实例方法锁定当前对象，静态方法锁定当前类**
  - JVM通过在方法访问标识符(flags)中加入**ACC_SYNCHRONIZED**来实现同步功能。’当一个线程访问方法时，会去检查是否存在ACC_SYNCHRONIZED标识，如果存在，则要获得对应的monitor锁，方法结束则释放monitor锁。
- 同步代码块
  - **指定对象加锁**
  - JVM使用**monitorenter**和**monitorexit**两个指令实现同步
    - 一个线程执行同步代码块要获取锁，执行monitorenter指令；在执行完代码块之后要释放锁，执行monitorexit指令。
    - 会有两个monitorexit：最后一个monitorexit是保证在异常情况下，锁也可以得到释放，避免死锁。

**synchronized可重入的原理**

synchronized是可重入锁，底层维护一个**计数器**：当线程获取该锁时，计数器加一，再次获得该锁时继续加一；释放锁时，计数器减一。当计数器值为0时，表明该锁未被任何线程所持有，其它线程可以竞争获取锁。

![5e93156f6b17f9180f5bcd0f3fe78224.png](https://img-blog.csdnimg.cn/img_convert/5e93156f6b17f9180f5bcd0f3fe78224.png)

---

**锁优化策略**

**synchronized版本迭代**

JDK1.6前 synchronized属于**重量级锁**，效率低下。

- 监视器锁（monitor）依赖于底层操作系统的 Mutex Lock 实现，Java 的线程映射到操作系统的原生线程之上。
- 如果要挂起或者唤醒一个线程，都需要操作系统帮忙完成，线程切换需要**从用户态转换到内核态**，成本较高

JDK1.6 对 synchronized 做了很多优化，引入了自适应自旋、锁消除、锁粗化、偏向锁和轻量级锁等提高锁的效率。

**锁的4种状态 / monitor有几种类型** [参考](https://blog.csdn.net/weixin_39606638/article/details/110413494)

- 无锁：没有对资源进行锁定，所有的线程都能访问并修改同一个资源，但只有一个线程能成功。

- 偏向锁：初次执行到synchronized代码块时变成偏向锁。偏向于当前获得它的线程，执行完后并不会主动释放偏向锁。这样同一个线程再次访问时不用再获取锁。

- 轻量级锁 ：偏向锁被其他线程访问时升级为轻量级锁。将对象头中的markwork部分CAS更新为线程id，更新成功则表示已经成功的获取了锁。否则线程会通过自旋（**自适应自旋锁**）获取锁，从而提高性能。

  自适应自旋锁：自旋时间为同一个锁上一次线程自旋获得锁的时间。如果自旋很少成功的就不自旋，避免浪费CPU资源。

- 重量级锁：轻量级锁达到最大自旋次数时升级为重量级锁。一个线程获取锁后，其余线程都会处于阻塞状态。但线程切换需要**从用户态转换到内核态**，消耗大。

<img src="https://img-blog.csdnimg.cn/20200603161323889.png" alt="在这里插入图片描述" style="zoom: 80%;" />

**偏向锁、轻量级锁和重量级锁的区别**

| 锁       | 优点                                 | 缺点                                         | 适用场景               |
| -------- | :----------------------------------- | -------------------------------------------- | ---------------------- |
| 偏向锁   | 加解锁不需要额外的消耗，性能好       | 如果线程间存在锁竞争，会带来额外的锁撤销消耗 | 只有一个线程访问同步块 |
| 轻量级锁 | 线程竞争会自旋，不会阻塞，响应速度快 | 自旋会消耗CPU                                | 追求响应速度           |
| 重量级锁 | 线程竞争不会自旋，不会消耗CPU        | 线程阻塞，响应时间慢                         | 追求吞吐量             |

**编码过程中锁优化的思路**

- 减少锁持有时间：缩小加锁的范围。对一个方法加锁，不如对需要同步的几行代码加锁；
- 减小锁粒度：如ConcurrentHashMap对segment加锁而不是整个map加锁
- 锁分离：如把锁划分为的读锁和写锁，读锁之间不互斥
- 锁膨胀（锁粗化）：扩大加锁范围，把这些不连续的同步语句进行一次性加锁解锁，减少了加锁解锁的次数。
- 锁消除：编译器根据代码逃逸技术，若判断到一段代码中堆上的数据不会逃逸出当前线程（即不会影响线程空间外的数据），则可以认为这段代码是线程安全的，不必加锁。

---

**synchronized Lock/ReentrantLock区别**⭐

- synchronized 在**JVM层面**，是Java内置关键字；Lock是个Java类；
- synchronized **自动锁**，不需要手动获取和释放锁，发生异常会自动释放锁，不会造成死锁；lock 需要手动加锁和释放锁，需将unlock()方法写在finally块，否则发生异常时会造成死锁。
- synchronized **非公平锁**；Lock默认是非公平锁，也可以是公平锁
- synchronized **不可以知道**有没有成功获取锁；Lock 可以知道有没有成功获取锁
- synchronized **不可中断**；lock可中断。
- synchronized 可以给类、方法、代码块加锁；lock 只能给代码块加锁。

**synchronized CAS 比较**

- synchronized 是**悲观锁**，抢占式阻塞；CAS 是**乐观锁**，非阻塞
- 原理……

**synchronized volatile区别**

- volatile 是变量修饰符；synchronized 可以修饰类、方法、变量。
- volatile 仅能实现变量的修改可见性，不能保证原子性；而 synchronized 则可以保证变量的修改可见性和原子性。
- volatile 不会造成线程的阻塞；synchronized 可能会造成线程的阻塞。
- volatile标记的变量不会被编译器优化；synchronized标记的变量可以被编译器优化。
- volatile关键字是线程同步的轻量级实现，所以volatile性能肯定比synchronized关键字要好。但synchronized关键字在JavaSE1.6之后进行了优化之后效率有了显著提升，实际开发中使用 synchronized 关键字的场景还是更多一些。

#### final

**用法** [参考](https://www.yuque.com/forlogen-d1hka/vlls8p/zlhgb3) 

- 修饰类不能被继承。如 String、基本类型的包装类、BigInteger 和 BigDecimal 等。
- 修饰方法不能被重写。所有final类的成员方法都会被隐式地指定为 final 方法。

- 修饰变量只能被赋值一次。
  - 修饰基本数据类型时，该值在初始化后不能改变。
  - 修饰引用类型时，引用的对象在初始化后不能改变（该对象的内容可以发生变化）

**final修饰的变量为什么能保证不变** [参考](https://www.cnblogs.com/chansblogs/p/8387801.html)

编译前**编译器**会检查final修饰的关键字是否保持不变，若变化则报错

编译后final相关信息不会保存在类文件中，变量可变

---

**遵守两个重排序规则：保证初始化后的可见性**	

- 构造函数内对一个final域的写入，与随后引用的赋值，这两个操作之间不能重排序。（Store Store 屏障）

  > 先写再赋，言外之意：在对象引用为任意线程可见之前，对象的final域已经被正确的初始化过了。

- 初次读一个包含final域的对象引用，与随后初次读这个final域，这两个操作之间不能重排序。（Load Load 屏障）

  > 言外之意：只有得到了包含final域对象的引用，才能后读到final域的值。

**底层原理 / 内存语义**

- 编译器会在 final 域的写后，构造方法的 return 前插入一个 Store Store 屏障，确保对象引用为任意线程可见前其已初始化。 
- 编译器在读 final 域操作的前面插入一个 Load Load 屏障，确保在读final 域前一定会先读包含这个 final 域的对象引用。

---

**优点**

- final变量可以安全的在多线程环境下进行共享，而不需要额外的同步开销
- JVM和Java应用都会缓存final变量，提高性能

- 使用final关键字，JVM会对方法、变量及类进行优化

**什么是不可变对象，它对写并发应用有什么帮助？**

- 状态创建后不再修改；
- 所有域都是 final 类型
- 被正确创建（创建期间没有发生 this 引用的逸出）。

不可变对象保证了对象的内存**可见性**，对不可变对象的读取不需要额外的同步手段，提升了代码执行效率。

### 锁 5

**Lock接口** 是 juc 包的顶层接口，在类库层面实现同步，利用了 **volatile和AQS**

#### AQS⭐

**为什么它是JUC下重要基石？**

AQS 队列同步器是构建锁或其他同步组件的基础框架
![image-20210202173123465](https://i.loli.net/2021/02/02/f1tiFJPgY53xvUh.png)

**AQS 原理** [参考](http://www.mianshigee.com/question/10037lhe) 

- 使用一个volatile修饰的int变量来表示**同步状态**，通过CAS修改同步状态值 (如0表示未锁定,1表示锁定)
- 如果共享资源空闲，则将当前请求资源的线程设置为**工作线程**
- 如果共享资源被占用，则将线程封装成一个Node节点，通过CAS将节点放入FIFO的**CLH同步队列**尾部。此时节点会自旋等待，直到获取同步状态才会从自旋中退出。
  - 非公平锁：谁拿到锁就是谁的。只要CAS设置同步状态成功即可获取锁
  - 公平锁：FIFO。只有前驱节点是头节点的才能尝试获取同步状态，工作线程释放锁时会修改同步状态并及唤醒后继节点。

> CLH(Craig,Landin,and Hagersten)队列是一个**虚拟的双向队列**（即不存在队列实例，仅存在结点之间的关联关系）。

<img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91c2VyLWdvbGQtY2RuLnhpdHUuaW8vMjAxOS8xMS8yNS8xNmVhMDQ3Njc4NGNkMzJi?x-oss-process=image/format,png" alt="AQS原理图" style="zoom: 80%;" />

<img src="https://user-gold-cdn.xitu.io/2018/5/3/163261637c5fc765?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt="èªæè·åéæ´ä½ç¤ºæå¾.png" style="zoom: 67%;" />

**AQS 对资源的共享方式**

- Exclusive（独占）：只有一个线程能获取资源，如ReentrantLock。又可分为公平锁和非公平锁：
- Share（共享）：多个线程获取资源，如Semaphore、CountDownLatch、 CyclicBarrier、ReadWriteLock 。

**AQS应用实例**

- 重入锁ReentrantLock ……

- CountDownLatch
  - 任务分为N个子线程去执行，state也初始化为N（注意N要与线程个数一致）。
  - N个子线程并行执行，每个子线程执行完后countDown()一次，state减1。
  - 等到所有子线程都执行完后(即state=0)，会unpark()主调用线程，然后主调用线程就会从await()函数返回，继续后余动作。

**如何自定义同步器**

同步器的设计是基于模板方法模式的，自定义步骤如下：

- 使用者**继承**AbstractQueuedSynchronizer并**重写**其指定的方法，并使用同步器提供的3个方法来**访问或修改同步状态**。

  > `getState`、`setState` 和 `compareAndSetState` ，它们保证状态改变是安全的

- 将AQS组合在自定义同步组件的实现中，并**调用其模板方法**，这些模板方法会调用使用者重写的方法。

  > isHeldExclusively() //该线程是否正在独占资源。只有用到condition才需要去实现它。
  >
  > tryAcquire(int) //独占方式尝试获取资源，成功则返回true，失败则返回false。
  > tryRelease(int) //独占方式尝试释放资源，成功则返回true，失败则返回false。
  >
  > tryAcquireShared(int) //共享方式尝试获取资源。负数表示失败；0表示成功但没有可用资源；正数表示成功且有剩余资源。
  > tryReleaseShared(int) //共享方式尝试释放资源，成功则返回true，失败则返回false。
  >
  > 一般来说，自定义同步器要么是独占方法，要么是共享方式，他们也只需实现`tryAcquire-tryRelease`、`tryAcquireShared-tryReleaseShared`中的一种即可。但AQS也支持自定义同步器同时实现独占和共享两种方式，如`ReentrantReadWriteLock`。

#### 重入锁⭐

**什么是可重入锁（ReentrantLock）？**

ReentrantLock是实现Lock接口的一个类，支持重入性，当前线程获取该锁再次获取不会被阻塞。

**重入性的实现原理**

- 可重入：线程获取锁时，如果已获得锁的线程是当前线程的话则直接获取成功（工作线程）
- 锁释放：由于锁会被获取n次，那么只有锁在被释放同样的n次之后，该锁才算是完全释放成功。（同步状态）
  - state初始值为0，表示未锁定状态。
  - A线程lock()时，会调用tryAcquire()独占该锁并将state+1。A线程可以重复获取此锁并累加state
  - 其他线程再tryAcquire()时就会失败，直到A线程unlock()到state=0为止

#### 读写锁⭐

读写锁在同一时刻允许多个读线程访问，在写线程访问时，所有的读写线程均阻塞。

 **实现原理**

- 在AQS**状态变量**上维护读线程和写线程的状态。将变量切分成了两个部分，高 16 位表示读，低 16 位表示写。**以线程为单位。**


- 写锁是可重入排他锁
  - 获取：如果无锁或当前线程已经获得了写锁则增加写状态；如果读锁已被获取或其他线程已获得写锁则等待。
  - 释放：每次释放减少写状态，当写状态为 0 时表示写锁已被释放。
- 读锁是可重入共享锁
  - 获取：如果无锁或当前线程已经获取了读锁则增加读状态；如果写锁已被获取则等待。
  - 释放：每次释放会减少读状态，减少的值是 `1<<16`，读锁的释放是线程安全的。

**锁降级**

降级意为写锁降级为读锁，其实就是释放写锁前需**获取读锁**

目的是保证数据可见性，防止其他线程加写锁修改数据。如果当前线程不获取读锁而直接释放写锁，假设后面另一个线程获取写锁并修改数据，则当前线程无法感知数据更新。

> **读写锁有什么问题？**
>
> 读时加锁性能差？读可以不用加锁，采用乐观锁的思想。读写锁中如果有线程正在读，写线程需要等待读线程释放锁后才能获取写锁，即读的过程中不允许写，为了能进一步提高效率可以用StampedLock，这种是带版本号的乐观锁。

#### Condition

**Condition结构** [参考](https://blog.csdn.net/a1439775520/article/details/98471610)

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190804170525878.png)

AQS有一个同步队列和多个等待队列，队列含Node节点。Condition是AQS的内部类，每个Condition对象都包含**一个等待队列**。等待队列是一个FIFO的队列，队列中每个节点都包含了一个线程引用。

**等待 await()**

<img src="https://img-blog.csdnimg.cn/20190804170556995.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ExNDM5Nzc1NTIw,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" style="zoom:50%;" />

同步队列的首节点会释放锁并唤醒同步队列中的后继节点，然后移动到Condition的等待队列尾部进入等待状态

**通知 signal()**

<img src="https://img-blog.csdnimg.cn/20190804170719441.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ExNDM5Nzc1NTIw,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" style="zoom:80%;" />

将等待队列中等待最长时间的节点（首节点）移到同步队列尾部，然后唤醒该节点

### 并发容器 并发类 6 7 8

#### ConcurrentHashMap⭐

ConcurrentHashMap是一个线程安全且高效的HashMap，用于解决 HashMap 的线程不安全问题和 HashTable 的低效问题

**原理**

**JDK1.7** [补充](https://thinkwon.blog.csdn.net/article/details/104588551)

<img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy83ODk2ODkwLTY0NTgzNmU3MjJjMmE5ZjkucG5n?x-oss-process=image/format,png" alt="img" style="zoom:67%;" />

- segment数组包含哈希表若干个桶，每个桶包含一个HashEntry数组，每个数组元素对应一个链表。

  segment分段锁使得当前数据段锁住时，其他数据段也能被其他线程访问。

- 三个操作
  - `get`：**不用加锁，除非读到空值才加锁重读**。因为共享变量使用 **volatile** 修饰。（首先经过一次再散列得到一个 hash 值，再用这个 hash 值定位到 Segment，然后通过散列算法定位到元素。）
  
  - `put`：**必须加锁**，segment继承了**ReentrantLock**充当锁的角色。线程会先调用tryLock获得锁，失败则先自旋等待其他线程释放锁，直至指定的次数**MAX_SCAN_RETRIES**才阻塞，提高效率。（首先定位到 Segment，然后进行插入操作。首先判断是否需要对 Segment 里的 HashEntry 数组进行扩容，然后定位添加元素的位置，然后将其放入数组。）
  
    > 自旋最大次数：static final int MAX_SCAN_RETRIES = Runtime.getRuntime().availableProcessors() > 1 ? 64 : 1;
  
  - `size`：统计每个 Segment 桶的大小然后求和。因为 count 变化几率很小，因此先尝试两次不加锁统计，如果容器发生变化再加锁统计。判断容器是否发生变化根据 **modCount** 确定，每次put、remove、clean操作其值都会加1。

**JDK1.8**

<img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy83ODk2ODkwLWVjODU2MDM5NWUyNTU0N2EucG5n?x-oss-process=image/format,png" alt="img" style="zoom:67%;" />

- jdk1.7查询时遍历链表效率太低，故 jdk1.8 抛弃了Segment 分段锁，将 1.7 中存放数据的 HashEntry 数组改为 Node 数组，**数据结构类似于1.8后的HashMap。**

  某个槽内的元素个数达到8且 table 容量大于64时，链表转为红黑树。当某个槽内的元素减少到6时，由红黑树重新转为链表。

  > 在转化过程中，使用同步块锁住当前槽的首元素，防止其他线程对当前槽进行增删改操作，转化完成后 CAS 替换原有链表。由于 TreeNode 节点也存储了 next 引用，因此红黑树转为链表很简单，只需从 first 元素开始遍历所有节点，并把节点从 TreeNode 转为 Node 类型即可，当构造好新链表后同样用 CAS 替换红黑树。


- 三个操作

  - `get`：与jdk1.7相似，无需加锁
  - `put`： **CAS + synchronized**。定位到桶判断第一个结点：
    - 为空则CAS插入
    - 为-1则说明在扩容，跟着一起扩容
    - 否则加锁put
  - `size`：用baseCount来存储当前的节点个数（CAS更新）

---

**Concurrenthashmap和Hashtable的区别**⭐ [参考](https://blog.csdn.net/xiewenfeng520/article/details/107120578)

- **数据结构**：ConcurrentHashMap……Hashtable 和 JDK1.7的 HashMap 类似，采用数组+链表的形式
- **线程安全原理**：ConcurrentHashMap……并发效率更高；Hashtable内部方法经过 `synchronized` 修饰，效率低
- **迭代时修改**：ConcurrentHashMap 允许在迭代时修改内容，不会抛出ConcurrentModificationException；Hashtable 不允许在迭代时修改内容，否则会抛出ConcurrentModificationException 异常；       
- 出现的版本不同：Hashtable 在 JDK1.0 的时候就存在了，并在 JDK1.2 版本中实现了 Map 接口，成为了集合框架的一员。ConcurrentHashMap 则是在 JDK1.5 中才出现的      

**ConcurrentHashMap和SynchronizedMap 有什么区别？** [参考](https://www.bilibili.com/read/cv2100711/)

 SynchronizedMap 和 hashtable 的唯一不同是可以用`Collections.synchronizedMap()`方法把任何的Map变成同步版本。

故答案参考 Concurrenthashmap和Hashtable的区别

**ConcurrentHashMap和HashMap的区别** [参考](https://blog.csdn.net/sinat_40482939/article/details/108014484)

- 原理不同……
- HashMap的键值对允许有null，但是ConCurrentHashMap 和 HashTable 都不允许 

---

**如何在很短的时间内将大量数据插入到ConcurrentHashMap**

- 尽可能减少扩容事件的发生。主要通过配置合理的容量大小和扩容因子；参照HashMap
- 尽可能避免锁升级。在put方法中会使用synchonized对头节点进行加锁，故可将数据通过ConcurrentHashMap的spread方法进行预处理，将存在hash冲突的数据放在一起，使用单线程进行put操作，保证锁仅停留在**偏向锁**级别，不会升级。

#### 阻塞队列

**什么是阻塞队列？阻塞队列的实现原理是什么？** [参考](https://blog.csdn.net/chenchaofuck1/article/details/51660119)

阻塞队列（BlockingQueue）是一个支持两个附加操作的队列。这两个附加的操作是：在队列为空时，获取元素的线程会等待队列变为非空。当队列满时，存储元素的线程会等待队列可用。

原理是Lock的**Condition**接口和**可重入锁**

主要用途并不是作为容器，而是作为线程同步的的工具如**生产者消费者**

**JDK7 提供了 7 个阻塞队列**

- ArrayBlockingQueue ：一个由数组结构组成的有界阻塞队列。
- LinkedBlockingQueue ：一个由链表结构组成的有界阻塞队列。
- PriorityBlockingQueue ：一个支持优先级排序的无界阻塞队列。
- DelayQueue：一个使用优先级队列实现的无界阻塞队列。
- SynchronousQueue：一个不存储元素的阻塞队列。
- LinkedTransferQueue：一个由链表结构组成的无界阻塞队列。
- LinkedBlockingDeque：一个由链表结构组成的双向阻塞队列。

#### 原子类

**什么是原子操作？在 Java Concurrency API 中有哪些原子类(atomic classes)？**

原子操作（atomic operation）意为”不可被中断的一个或一系列操作” ，是在多线程环境下避免数据不一致的手段。

- AtomicInteger 原子更新整形、 AtomicLong 原子更新长整型、AtomicBoolean 原子更新布尔类型。
- AtomicIntegerArray 原子更新整形数组、 AtomicLongArray 原子更新长整型数组、 AtomicReferenceArray 原子更新引用数组。
- AtomicReference 原子更新引用、AtomicMarkableReference 原子更新带有标记的引用，AtomicStampedReference 原子更新带有版本号的引用，关联一个整数值作为版本号，解决 ABA 问题。
- AtomicIntegerFieldUpdater 原子更新整形字段、 AtomicLongFieldUpdater 原子更新长整形字段、AtomicReferenceFieldUpdater 原子更新引用类型字段。

**说一下 atomic 的原理？**[参考](https://blog.csdn.net/wuzhiwei549/article/details/82621947)

atomic底层是**CAS**保证线程同步的，比如AtomicInteger类的increamentAndGet方法底层是通过Unsafe类的方法实现的，而Unsafe类是java提供CAS机制的类。介绍CAS……

### 线程 4

#### 线程创建

**线程创建的方法**

- 继承 Thread 类并重写 `run` 方法。实现简单，但不符合里氏替换原则，不可以继承其他类。
- 实现 Runnable 接口并重写 `run` 方法。避免了单继承局限性，实现解耦。
- 实现 Callable 接口并重写 `call` 方法。可以获取线程执行结果的返回值，并且可以抛出异常。
- 使用 Executors 工具类创建线程池

**说一下 Runnable 和 Callable 有什么区别？**

- Runnable 接口 run 方法无**返回值**；Callable 接口 call 方法有返回值（泛型）
- Runnable 接口 run 方法只能抛出运行时**异常**且无法捕获；Callable 接口 call 方法允许抛出异常且可以捕获异常

**什么是 Callable 和 Future?**

所以说 Callable用于产生结果，Future 用于获取结果。

- Callable 接口类似于 Runnable，但是 Runnable无返回值，且只能只能抛出运行时异常；而 Callable能获取异步执行结果，抛出异常

- Future 接口表示异步任务，是一个可能还没有完成的异步任务的结果。

**线程的 run()和 start()有什么区别？**

- start() 方法用于启动线程，run() 方法用于执行线程的运行时代码。
- start() 会执行线程的相应准备工作，然后自动执行 run() 方法的内容，这是真正的多线程工作；而直接执行 run() 方法，会把 run 方法当成一个主线程下的普通方法去执行，并不是多线程工作。故我们需使用start()方法而非直接调用 run() 方法启动线程。
- run() 可以重复调用，而 start() 只能调用一次。

#### 线程状态⭐

> 比进程多了两个

- NEW：创建态，线程被创建但未启动。还未调用 `start`  方法。
- RUNNABLE：执行态，Java 将操作系统中的就绪和运行统称为 RUNNABLE。此时线程有可能在等待时间片，也有可能在执行。
- BLOCKED：阻塞态，可能由于锁被其他线程占用。
- TERMINATED：终止态，当前线程已执行完毕或异常退出。
- WAITING：等待态，线程没有被分配 CPU 时间片，需要其他线程通知或中断。可能调用了无参的 `wait` 和 `join` 方法。
- TIME_WAITING：超时等待态，等待超时后自行返回。可能调用了带参的 `wait` 和 `join` 方法。

<img src="https://images2018.cnblogs.com/blog/930824/201807/930824-20180715222029724-1669695888.jpg" alt="img" style="zoom: 67%;" />

> **线程有哪些状态？wait和block的区别？Wait超时后会怎样？**[参考](https://www.zhihu.com/question/27654579)
>
> 其实wait的线程被唤醒后其实会进入block的状态去抢锁，而国内大部分博客都画成唤醒后进入就绪状态。因为wait是在同步代码块中运行的，所以被唤醒后会要去抢锁，抢到锁才会进入就绪状态

#### 线程方法⭐

**sleep() wait() notify()的区别**⭐ [参考](https://www.it610.com/article/1282538080984645632.htm)

- wait()：Object类方法；调用后线程会进入超时等待状态或等待状态；会释放锁
- notify()：Object类方法；调用后线程会被唤醒
- sleep()：Thread类方法；调用后线程会进入超时等待状态；不会释放锁

> wait 等线程通信方法必须搭配 synchronize 一起使用；而 sleep 不需要 [Lost Wake-Up Problem](https://juejin.cn/post/6844904088505679879#heading-1)

**如何中断/终止一个正在运行的线程？如何安全优雅地实现**⭐ [参考](https://blog.csdn.net/qq_33591903/article/details/108616336)

- 使用**volatile修饰的boolean变量**中断线程
- 使用**interrupt方法**中断线程。[参考](https://segmentfault.com/a/1190000023475814)
  - 如果线程处于正常活动状态，会将该线程的中断标志设置为true，可利用**中断标志**结束线程
  - 如果线程处于阻塞状态，将退出被阻塞状态（JVM?），抛出interruptedException异常并将中断标志设置成 false。若像继续利用中断标志结束线程，需再调用一次interrupt方法将中断标志设置为true。

---

**Java实现线程同步的方法**⭐ [参考](https://blog.csdn.net/weixin_41835916/article/details/81604785)

- 等待通知机制 wait/notify
- 阻塞队列
- 自动锁sychronized
- 手动锁Lock
- 原子类
- volatile
- ThreadLocal

**线程通信的方式** [参考](https://blog.csdn.net/u011635492/article/details/83043212)

- 等待通知机制 wait/notify
- 阻塞队列（生产者-消费者模型）
- join
- Condition
- 管道

**生产者-消费者模型** [参考](https://blog.csdn.net/lvxin15353715790/article/details/89143121)

- 解决生产者和消费者的强耦合问题
- 生产者和消费者彼此之间不直接通讯，而通过阻塞队列来通讯。生产者生产的数据直接放入阻塞队列，阻塞队列满时生产阻塞。消费者直接从阻塞队列里取出生产的数据，阻塞队列空时消费阻塞。

#### ThreadLocal⭐

**ThreadLocal 是什么？**

ThreadLocal是一个本地线程的副本变量工具类，可为每个线程创建单独的副本

**存在的问题**

![img](https://pic4.zhimg.com/80/v2-602befabc36ae4bdfcd2e7593abc2d87_720w.jpg)

- **内存泄漏**。每个Thread包含一个 ThreadLocalMap 对象，里面的Entry[]数组 key 为 ThreadLocal 的弱引用，value 为存储内容的强引用。因此当 ThreadLocal 被垃圾回收后，value 依旧不会被释放。
- 线程复用产生**脏数据**。线程池会重用 Thread 对象，因此与 Thread 绑定的 ThreadLocal 也会被重用。

---

**ThreadLocal内存泄漏解决方案？**

ThreadLocalMap中已经考虑了这种情况，调用 `set()`、`get()`、`remove()` 方法时，会清理掉 key 为 null 的记录

**那ThreadLocal为什么使用弱引用**

保证ThreadLocal能被回收。ThreadLocal的引用对象被回收时，即使没有手动删除ThreadLocal，ThreadLocal也能被回收

> **内存泄漏的根源**：ThreadLocalMap的生命周期跟Thread一样长，只能手动删除对应key以防止内存泄漏，而不是因为弱引用。

**ThreadLocal如何解决哈希冲突**

开放地址法中的线性探测法……

---



### 线程池 9 10

#### 线程池概述

**线程池定义**

在面向对象编程中，创建和销毁对象是很费时间的，因为创建一个对象要获取内存资源或者其它更多资源。

线程池顾名思义就是事先创建若干个可执行的线程放入一个池（容器）中，需要的时候从池中获取线程不用自行创建，使用完毕不需要销毁线程而是放回池中，从而减少创建和销毁线程对象的开销。

**线程池好处**

- 降低资源消耗，复用已创建的线程，降低开销、控制最大并发数。
- 隔离线程环境，可以配置独立线程池，将较慢的线程与较快的隔离开，避免相互影响。
- 实现任务线程队列缓冲策略和拒绝机制。
- 实现某些与时间相关的功能，如定时执行、周期执行等。

**线程池状态**

- RUNNING：这是最正常的状态，接受新的任务，处理等待队列中的任务。
- SHUTDOWN：不接受新的任务提交，但是会继续处理等待队列中的任务。
- STOP：不接受新的任务提交，不再处理等待队列中的任务，中断正在执行任务的线程。
- TIDYING：所有的任务都销毁了，workCount 为 0，线程池的状态在转换为 TIDYING 状态时，会执行钩子方法 terminated()。
- TERMINATED：terminated()方法结束后，线程池的状态就会变成这个。

**线程池关闭**

可以调用 `shutdown` 或 `shutdownNow` 方法关闭线程池，原理是遍历线程池中的工作线程，逐个调用 `interrupt` 方法中断线程。

- `shutdownNow` 首先将线程池的状态设为 STOP，然后尝试停止正在执行或暂停任务的线程，并返回等待执行任务的列表。
- `shutdown` 只是将线程池的状态设为 SHUTDOWN，然后中断没有正在执行任务的线程。
- 通常调用 `shutdown` 来关闭线程池，如果任务不一定要执行完可调用 `shutdownNow`。

**什么是 Executor 框架？为什么使用 Executor 框架？**

Executor 框架是一个根据一组执行策略调用，调度，执行和控制的异步任务的框架。

利用Executors框架可以非常方便的创建一个线程池。

#### 线程池原理⭐

**线程池参数⭐**

> 前4个结合线程池流程

① corePoolSize：核心线程数。

② maximumPoolSize：线程最大数。

③ keepAliveTime：线程空闲时间。超时则大于corePoolSize的多余线程会被回收。

④ unit：keepAliveTime 的时间单位。

⑤ workQueue：工作队列。

⑥ threadFactory：线程工厂。用来生产一组相同任务的线程。

⑦ handler：拒绝策略。工作队列已满且线程数量达到线程最大数时，新任务到达后采用的拒绝策略。

- AbortPolicy 丢弃任务并抛出异常  默认 
- DiscardPolicy 丢弃任务但不抛出异常
- CallerRunsPolicy 重新尝试提交任务
- DiscardOldestPolicy 丢弃队列里等待最久的任务并将新任务加入队列

**怎么确定业务中线程池的要开启的线程数？公式? / 你怎么设置参数（I/O密集型、计算密集型）** [参考](https://blog.csdn.net/qq_34417408/article/details/78895573?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-15.control&dist_request_id=&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-15.control)

- CPU 密集型任务：消耗的主要是 CPU 资源。**N（CPU 核心数）+1**。

  多出来的一个线程是为了防止缺页中断或其它原因导致的任务暂停。一旦任务暂停CPU 就会处于空闲状态，而多出来的一个线程就可以充分利用 CPU 的空闲时间。

- I/O 密集型任务：会消耗大部分时间来处理 I/O 。**2N**

  处理 I/O 的时间段内不会占用 CPU ，可以将 CPU 交出给其它线程使用，多设N个。

- 常规的业务操作：如通过一个线程池实现向用户定时推送消息的业务。**N *（1+WT（线程等待时间）/ST（线程运行时间））**

**对于线程池参数的设定,你有没有自己的一套方案？怎么设置核心线程池数和最大线程池数**  [参考](https://www.cnblogs.com/thisiswhy/p/12690630.html)



---

**线程池流程⭐**

- 核心线程池未满：创建新线程
- 核心线程池已满，工作队列未满：将线程封装成任务 Worker 存储在工作队列，Worker 在执行完任务后，线程池会循环获取工作队列中的任务来执行。
- 工作队列已满，线程数小于最大线程数：创建新线程，需要获取全局锁。
- 超过最大线程数，按照拒绝策略来处理任务。

![img](https://upload-images.jianshu.io/upload_images/6024478-88ee7b20f8f45825.png?imageMogr2/auto-orient/strip|imageView2/2/w/937/format/webp)

**如果你提交任务时，核心线程池已满，这时会发生什么**

- 如果使用的是无界队列如LinkedBlockingQueue，可以无限存放任务
- 如果使用的是有界队列比如 ArrayBlockingQueue，看上面处理流程

**假如让你实现一个线程池，你会怎么实现？**

- 参数
- 流程
- 数据结构：线程池 阻塞队列……

（我使用list存储核心线程，然后不够再扩容，用完了经过最大等待时间再回收......） 面试官说其实数据结构用数组、[链表]()都可以，有空多看看[源码]()的设计思路线程池阻塞队列 

#### 线程池创建⭐

**线程池的创建方式**

- Executors的静态方法（底层仍调用ThreadPoolExecutor的构造函数）
  - `newFixedThreadPool ` 定长线程池，可控制线程最大并发数，超出的线程会在队列中等待。
  - `newSingleThreadPool` 单线程线程池，只有唯一的工作线程来执行任务，保证所有任务按指定顺序(FIFO, LIFO, 优先级)执行
  - `newCachedThreadPool` 可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程。
  - `newScheduledThreadPool` 可定期或延时执行任务的定长线程池，支持定时及周期性任务执行。
- ThreaPoolExecutor的构造函数：可以自定线程池参数

**线程池OOM / 实现线程池为什么不用Executors的静态方法生成固定的那几个？ ** [参考](https://blog.csdn.net/weixin_37968613/article/details/104490441)

Executors静态方法的弊端

- `newFixedThreadPool` 和 `newSingleThreadPool`：工作队列最大数是 Integer.MAX_VALUE，可能堆积很多请求，造成OOM
- `newCachedThreadPool` 和 `newScheduledThreadPool`：线程数最大数是 Integer.MAX_VALUE，可能创建很多线程，造成OOM

> 《阿里巴巴Java开发手册》中强制线程池**不允许使用 Executors 去创建，而是通过 ThreadPoolExecutor 的方式**，这样的处理方式让写的同学更加明确线程池的运行规则，规避资源耗尽的风险

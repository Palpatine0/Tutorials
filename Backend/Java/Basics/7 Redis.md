###  概述

#### Redis概述

**为什么用Redis / Redis优点**

- 读写性能优异。读速度是110000次/s，写速度是81000次/s。
- 数据结构丰富。String、list、hash、set、zset
- 支持持久化。RDB AOF
- 支持事务。所有操作都是原子性的，还支持对几个操作合并后的原子性执行。
- 支持主从复制，读写分离。

> **为什么有了Redis还要Mysql？** [参考](https://www.v2ex.com/t/219551)
>
> - Redis 持久化不是实时的
> - Redis 只能用键查询
> - Redis 内存占用巨大成本高

**Redis缺点**

- 性能瓶颈：内存、IO
- 主从数据丢失：异步复制、脑裂
- 较难在线扩容：为避免这一问题，运维人员在系统上线时必须确保有足够的空间，这对资源造成了很大的浪费。

**Redis如何保证高并发，高可用？**

高并发：主从复制，读写分离。

高可用：复制、哨兵、集群。

> **高可用**（High Availability）通常指通过设计减少系统不能提供服务的时间。
> 如果一台系统能够不间断的提供服务，那么这台系统的可用性即为100%。那如果系统每运行100个时间单位，就会出现1个时间单位无法提供服务，那么该台系统的可用性是99%。
> 目前大部分企业的高可用目标是4个9，也就是99.99%，也就是允许这台系统的年停机时间为52.56分钟。
>
> 单机宕机：持久化

**如果redis出现故障比如断电宕机，如何避免数据丢失？**

- 单机：持久化
- 主从：异步复制、脑裂

#### Redis线程模型⭐

**Redis为什么这么快 / 使用单线程模型的原因**⭐

- 基于内存：将所有数据放在内存中，响应速度快
- IO多路复用（**核心**）：**能并发处理客户端的请求而不阻塞**。可暂停某个 IO 事件转而去处理另一个 IO 事件
- 单线程：避免了线程上下文切换带来的性能消耗
- 数据结构简单：操作简单

**Redis的性能瓶颈是什么**⭐ [参考](https://blog.csdn.net/qq_29066533/article/details/113706567) [参考](https://blog.csdn.net/kzadmxz/article/details/100573254)

- **内存**：redis将所有数据放在内存中，存放量取决于内存的多少

- **IO**（最主要）：虽然采用IO多路复用机制，但是**读写操作仍是同步IO**。一个请求耗时长时，后面的请求都要停止等待，从而影响整体性能。如**bigkey**

> Redis在6.0推出了多线程，可以在高并发场景下利用CPU多核**多线程读写客户端数据**，进一步提升server性能。但每个命令的真正操作依旧是单线程的。
>
> bigkey解决方法：一方面需要业务人员去规避（拆分等）；一方面Redis在4.0推出了lazy-free机制，把bigkey释放内存的耗时操作放在了异步线程中执行，降低对主线程的影响。
>
> Redis是单线程的，故CPU不是Redis的瓶颈

**Redis线程模型 / 文件事件处理器构成？** [参考](https://www.cnblogs.com/javastack/p/12848446.html)

<img src="https://img2020.cnblogs.com/other/1218593/202005/1218593-20200508090955090-2110581654.png" alt="img" style="zoom: 50%;" />

Redis基于Reactor模式开发了网络事件处理器，称为**文件事件处理器** (file event handler)

- 套接字：套接字准备好连接应答 、读取、写入、关闭等操作时，  与操作相对应的文件事件就会产生
- IO多路复用程序：同时监听多个套接字，并向文件事件分派器传送产生事件的套接字
- 文件事件分派器：**文件事件分派器队列的消费是单线程的，所以Redis才叫单线程模型。**
- 事件处理器：一个函数，定义了某个事件发生时服务器应该执行的操作

#### Redis事务

**ACID** [参考](https://blog.csdn.net/weixin_33918114/article/details/85703575?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.control&dist_request_id=&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.control)

- 原子性：不满足。对于事务队列
  - 入队时命令出错：自己包括前面已入队的全部失效，但后面仍正常
  - 执行时命令出错：只跳过自己这一出错命令
- 一致性：满足。执行过程中发生错误或进程被终结，都能保证数据的一致性
- 隔离性：满足。执行的过程中，不会处理其它命令
- 持久性：严格上都不满足，具体取决于持久化方式

### 缓存问题

#### 缓存击穿⭐

查询缓存没有但数据库有的数据（**同一数据**），导致请求都落到数据库上，给数据库造成很大的压力。

解决方案

1. 设置热点数据永远不过期
2. 加互斥锁。若KEY不存在则加锁查询，使得其他线程会阻塞而不会查询数据库

#### 缓存雪崩⭐

缓存同时间的大面积失效（**多个数据**），导致请求都会落到数据库上，数据库崩溃。

解决方案

1. 随机设置数据的过期时间，防止同一时间大量数据过期
2. 加锁排队，并发量不是特别多时
3. 增加相缓存标记，若缓存标记失效则更新缓存

#### 缓存穿透⭐

查询缓存和数据库中都没有的数据，导致请求都落到数据库上，给数据库造成很大的压力。

解决方案

1. **接口层增加校验**：如用户鉴权校验，id做基础校验，id<=0的直接拦截；

2. 缓存空对象：记录key-null，缓存有效时间可以设置短点，如30秒

   两个问题：

   - 占用空间
   - 即使设置了过期时间，缓存层和存储层的数据还是会有一段时间的**不一致**

<img src="https://pics6.baidu.com/feed/203fb80e7bec54e7a4ba970397d293564ec26a4d.jpeg?token=0068420533f90cb97750b10ce30053b8&amp;s=9A027C239B9E4DC848DDC4D6000080B2" alt="img" style="zoom:67%;" />

3. **布隆过滤器**⭐ [参考](https://zhuanlan.zhihu.com/p/112405834) [参考](https://blog.csdn.net/qq_41620205/article/details/103065316)

   布隆过滤器 = 位图+一系列哈希函数。底层是一个超级大的 bit 数组，元素默认为0。一个元素通过多个hash函数映射到这个 bit 数组上，并且将 0 改成 1。判断时只要有一个位为 0，那么说明这个 key 不存在。

   <img src="https://imgconvert.csdnimg.cn/aHR0cDovL3d3dy5tdXl1eGl6aS50b3Avd3AtY29udGVudC91cGxvYWRzLzIwMTkvMTEvNi0xNTczMTMxNDk5LnBuZw?x-oss-process=image/format,png" alt="如何在海量数据中判断某个数据是否存在？" style="zoom: 50%;" />

   **优点**
- 查询时间短，哈希直接查找。
- 所用空间小，每个元素只占1bit；

   **缺点**

- 存在一定的误判：判断不存在时一定不存在，但由于存在哈希冲突，可能不存在的元素被判断为存在。

  解决方法：使用容量更大的位图；rehash。

- 不支持删除：同样是由于存在哈希冲突

  解决方法（存疑）：对位图的每个单元增加计数器，计数器初始值为0，每映射一个数据，计数器加1，每删除一个数据，计数器减1。这样在删除数据时，只要计数器当前值大于1，该单元就不置为0

#### 双写一致性问题⭐

**双写一致性问题的解决**  [参考](https://zhuanlan.zhihu.com/p/59167071) [参考](https://www.cnblogs.com/liuqingzheng/p/11080680.html)

设置过期时间是保证最终一致性的解决方案

**1 读写请求串行化**

保证一定不会出现不一致的情况，但会导致系统的吞吐量会大幅度的降低

**2 先更新缓存，再更新数据库**



**3 先更新数据库，再更新缓存**         



**4 先删除缓存，再更新数据库**

问题：一个请求A进行更新操作，另一个请求B进行查询操作。**A先但被中断**

1. 请求A删除缓存
2. 请求B直接查询数据库，得一个旧值，将旧值写入缓存 
5. 请求A将新值写入数据库

解决方法：**延时双删策略**

1. 前面照常不变
2. 多了一个：休眠一定时间（1秒），再次删除缓存

**5 先更新数据库，再删除缓存**（使用）

问题：一个请求A进行更新操作，另一个请求B进行查询操作。**B先但被中断**

1. 缓存刚好失效，请求B查询数据库得旧值
2. 请求A将新值写入数据库，删除缓存
3. 请求B将查到的旧值写入缓存，产生脏数据

但是发生的几率特别小。因为问题的前提是B读数据库操作比A写数据库操作更慢，但其实数据库的读操作的速度远快于写操作的

### 数据结构与对象

#### 对象⭐

<img src="https://yqfile.alicdn.com/5becf2fd17aedf4df06d72874071ccf8f57d0580.png" alt="对象结构的逻辑图" style="zoom: 80%;" />

**redis有什么对象？分别在什么场景下**

| 对象   | 可以存储的值           | 操作                                                         | 应用场景                                                     |
| ------ | ---------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| STRING | 字符串、整数或者浮点数 | 对整个字符串或者字符串的其中一部分执行操作 对整数和浮点数执行自增或者自减操作 | 简单的键值对缓存。如短信验证码，配置信息等                   |
| LIST   | 列表                   | 从两端压入或者弹出元素 对单个或者多个元素进行修剪， 只保留一个范围内的元素 | 存储一些列表型的数据结构，适合按写入时间排序。如消息队列等。 |
| HASH   | 包含键值对的无序散列表 | 添加、获取、移除单个键值对 获取所有键值对 检查某个键是否存在 | 结构化的数据，一个对象。如商品详情，个人信息详情，新闻详情等。 |
| SET    | 无序集合               | 添加、获取、移除单个元素 检查一个元素是否存在于集合中 计算交集、并集、差集 从集合里面随机获取元素 | 交集、并集、差集的操作。如可以把两个人的粉丝列表整一个交集   |
| ZSET   | 有序集合               | 添加、获取、删除元素 根据分值范围或者成员来获取元素 计算一个键的排名 | 去重且可以排序。如获取排名前几名的用户                       |

#### 数据结构⭐

![image-20210323153101160](https://i.loli.net/2021/03/23/MZPbWHk36eXc1L7.png)

---

**ZSET对象**

当有序集合对象同时满足以下两个条件时，对象使用 ziplist 编码：

- 保存的元素数量小于128
- 保存的所有元素长度都小于64字节

以上两个条件也可以通过Redis配置文件zset-max-ziplist-entries 选项和 zset-max-ziplist-value 进行修改

**1 ZSET对象ziplist编码：压缩列表**

![img](https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy82OTkwMDM1LTRkODU5YzI1ZGY3NjM5M2UucG5nP2ltYWdlTW9ncjIvYXV0by1vcmllbnQvc3RyaXB8aW1hZ2VWaWV3Mi8yL3cvNzcxL2Zvcm1hdC93ZWJw?x-oss-process=image/format,png)

**为什么用压缩列表**

不要求所有元素大小相同，节约内存。

**缺点**

- 插入元素时需要重新分配新的内存空间，并将之前的内容一次性拷贝到新的地址。如果数据量太多，消耗很大
- 连锁更新 [参考](https://blog.csdn.net/qq_33774822/article/details/107108771)

**2 ZSET对象skiplist编码：字典+跳跃表** [参考](https://developer.aliyun.com/article/710228) [参考](https://developer.aliyun.com/article/712434?spm=a2c6h.13262185.0.0.9c905035R7L3Xo)

<img src="https://yqfile.alicdn.com/2f500aaec0b621fd36e68c594fa766ed672c7c7c.png" alt="_19" style="zoom: 67%;" />

**为什么有序集合需要同时使用跳跃表和字典来实现？**

为了保存两种结构各自的优点

- 字典结构以O(1)复杂度**单个**查找成语的分值；zscore命令
- 跳跃表**范围查询**时复杂度只要O(1)，zrank、zrange等命令

> 虽然zset结构同时使用跳跃表和字典来保存有序集合元素，但这两种数据结构都会通过指针来共享相同元素的成员和分值，所以同时使用跳跃表和字典来保存集合元素不会产生任何重复成员或分值，也不会因此浪费额外的内存。

---

**跳表** [参考](https://blog.csdn.net/wangxuelei036/article/details/106272680/?utm_medium=distribute.pc_relevant.none-task-blog-baidujs_baidulandingword-0&spm=1001.2101.3001.4242)

![image-20220518165705718](C:/Users/lxr/AppData/Roaming/Typora/typora-user-images/image-20220518165705718.png)

**跳表结构**

- zskiplist用于保存跳跃表信息
  - Header：指向跳跃表的表头节点
  - Tail：指向跳跃表的表尾节点
  - Level：记录跳跃表内的最大层数（表头节点不计算在内）
  - Length：记录跳跃表的长度，即目前节点的数量（表头节点不计算在内）

- zskiplistNode用于表示跳跃表节点
  - 层(level)：连线上带有数字箭头的是前进指针，前进节点可以挨个遍历，也可以一次跳过多个节点；箭头上的数字表示跨度。跨度实际上是用来**计算排位**(rank)的：在查找某个节点的过程中，将沿途访问过的所有层的跨度累计起来，得到的结果就是目标节点在跳跃表中的排位。
  - 后退(backward)指针：节点中用BW字样标记的是后退指针。后退节点每次只能退至前一个节点。
  - 分值(score)：节点按各自所保存的分值从小到大排列
  - 成员对象(obj)：节点中的o1、o2和o3

> 各个节点保存的成员对象必须是唯一的，但是多个节点保存的分值却可以是相同的：分值相同的节点将按照成员对象在字典中的大小来进行排序，成员对象较小的节点会排在前面(靠近表头的方向)，而成员对象较大的节点则会排在后面(靠近表尾的方向)。
>
> 注意表头节点和其他节点的构造是一样的：表头节点也有后退指针、分值和成员对象，不过表头节点的这些属性都不会被用到，所以图中省略了这些部分，只显示了表头节点的各个层。

**为什么不用二叉查找树**

数据单调时它会形成链表

**为什么不用红黑树**

- 跳跃表的操作简单又快速；红黑树的操作（查找、插入及删除）逻辑较复杂；
  - header和tail指针分别指向跳跃表的表头和表尾节点，能在O(1)复杂度快速找到表头节点和表尾节点
  - level属性，能用于在O(1)复杂度内获取跳跃表中层最大的那个节点
  - length记录节点数量，能在O(1)复杂度返回跳跃表长度
- 跳跃表更加方便进行范围查找；红黑树则不能

**跳表时间复杂度为 O(logn) 空间复杂度O(n) **[参考](https://blog.csdn.net/qq_34412579/article/details/101731935?spm=1001.2101.3001.6661.1&utm_medium=distribute.pc_relevant_t0.none-task-blog-2~default~CTRLIST~Rate-1.pc_relevant_antiscanv2&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-2~default~CTRLIST~Rate-1.pc_relevant_antiscanv2&utm_relevant_index=1)

- 查找：相当于在原始链表中一层层的每隔k个节点创建高层索引。然后从高层索引遍历，下个元素小则继续向右搜索，大则向下层搜索，类似二分查找。**故跳表是可以实现二分查找的有序链表**
- 删除：查找+删除元素。查找 O(logn) * 最多每层都有元素得删除 O(1) 
- 插入：查找+重建每层索引。查找 O(logn) * 重建每层索引 O(1) 要不要重建通过概率去判断 

---

**字典**

<img src="https://yqfile.alicdn.com/74aed0c22850880d3e45df00afe35d270cc692bb.png" alt="_6" style="zoom:67%;" />

**哈希表的扩展与收缩**

当哈希表中的数据过于紧密或疏松时，会对哈希表进行扩展与收缩。

- 收缩
  - 当哈希表的负载因子小于0.1时，程序自动开始对哈希表执行收缩操作（负载因子=哈希表已保存节点数量/哈希表大小）
- 扩展
  - 服务器目前没有在执行BGSAVE或BGREWRITEAOF命令，且哈希表的负载因子大于等于1
  - 服务器目前正在执行BGSAVE或BGREWRITEAOF命令，且哈希表的负载因子大于等于5
  - 当正在执行BGSAVE或BGREWRITEAOF命令时，redis会创建子进程，会用到写时复制技术，需要占用部分内存，此时尽可能避免对哈希表进行扩展，避免消耗不必要的内存

**重新散列rehash**

- 为字典的ht[1]分配空间
- 将ht[0]中的所有键值对rehash到ht[1]，释放ht[0]
- 将ht[1]设置为ht[0]
- 在ht[1]新建一个空白哈希表，为下一次rehash做准备

**渐进式rehash**

为了避免rehash对服务器性能造成影响，不是一次性将ht[0]里面所有的键值对全部rehash到ht[1]，而是分批次进行

- 如果要在字典里查找一个键，会先在ht[0]里面查找，如果没找到，会继续到ht[1]里进行查找。
- 新增加的键值对一律会被保存到ht[1]中，所以ht[0]里的键值对只减不增

### 内存

#### 过期键删除策略

Redis中同时使用**惰性过期和定期过期**两种过期策略。过期策略通常有以下三种：

- 定时过期：每个设置过期时间的key都创建一个定时器，过期则清除。

  可以立即清除过期数据，对内存很友好；但是会占用大量的CPU资源去处理过期数据，从而影响缓存的响应时间和吞吐量。

- **惰性过期**：只有访问一个key时，才会判断该key是否已过期，过期则清除。

  可以最大化地节省CPU资源，但对内存很不友好。极端情况可能出现大量过期数据没有被访问，不会被清除而占用大量内存。

- **定期过期**：每隔一定时间扫描数据库中一定数量的key，过期则清除。
  
  前两者的折中方案。可以在不同情况下使得CPU和内存资源达到最优的平衡效果。

**Redis key的过期时间和永久有效分别怎么设置？**

EXPIRE和PERSIST命令。

> expires字典会保存所有设置了过期时间的key的过期时间数据，其中，key是指向键空间中的某个键的指针，value是该键的毫秒精度的UNIX时间戳表示的过期时间。键空间是指该Redis集群中保存的所有键。

#### 内存淘汰策略

**Redis的内存用完了会发生什么 / 如果惰性过期和定期过期都没能删除过期键，如何处理**

触发内存淘汰策略，内存淘汰策略用于处理内存不足时的需要申请额外空间的数据

**Redis回收进程如何工作**

- 一个客户端运行了新的命令，添加了新的数据。
- Redis检查内存使用情况，如果大于maxmemory的限制， 则根据设定好的策略进行回收。
- 执行新命令，重复上述过程

**内存淘汰策略**

- 全局键
  - allkeys-lru：在键空间中，移除最近最少使用（最早使用）的key。  **最常用**
  - allkeys-random：在键空间中，随机移除某个key。
  - noeviction：新写入操作报错。

- 设置过期时间的键
  - volatile-lru：在设置了过期时间的键空间中，移除最近最少使用（最早使用）的key。
  - volatile-random：当在设置了过期时间的键空间中，随机移除某个key。
  - volatile-ttl：在设置了过期时间的键空间中，移除有更早过期时间的key。

### 持久化

持久化就是把内存的数据写到磁盘中去，防止服务宕机而导致内存数据丢失。

#### RDB

一定时间段将内存的数据以快照形式保存到硬盘中。（可通过配置文件中的save参数来定义快照的周期。）

**优点**

- 持久化方便。只有一个文件 dump.rdb
- 容灾性好。一个文件可以保存到安全的磁盘
- Copy On Write。使用 fork 子进程来完成写操作，主进程不会进行任何 IO 操作，保证了 redis 的高性能
- 启动效率比 AOF 高。

**缺点**

数据安全性低。RDB 是一段时间进行持久化，发生故障时会发生数据丢失。

#### AOF

将Redis每次执行的写命令记录到日志文件中

**优点**

- 数据安全。通过 append 模式写文件，发生故障时可以通过 redis-check-aof 工具解决数据一致性问题。
- rewrite 模式。AOF 文件没被 rewrite 之前（文件过大时会对命令进行合并重写），可以删除其中的某些命令（比如误操作的 flushall）

**缺点**

- AOF 文件比 RDB 文件大，且恢复速度慢。
- 数据集大的时候，比 rdb 启动效率低。

---

**RDB和AOF的区别**

|              | RDB                                          | AOF                                                          |
| :----------- | :------------------------------------------- | :----------------------------------------------------------- |
| 持久化方式   | 一定时间段记录数据快照                       | 实时记录每个写命令                                           |
| 持久化代价   | 高，消耗大量CPU和内存                        | 低，只占用磁盘IO                                             |
| 文件         | 压缩二进制，文件小                           | 写命令，文件大                                               |
| 数据完整性   | 不完整，取决于备份周期                       | 完整性高，取决于文件刷盘方式                                 |
| 宕机恢复时间 | 快                                           | 慢                                                           |
| 优先级       | **默认**的持久化方式                         | 两种方式同时开启时**优先选择AOF**。因为通常情况下AOF文件保存的数据集要比RDB完整 |
| 使用场景     | 数据备份、主从全量复制等对丢数据不敏感的场景 | 对于丢失数据敏感的场景                                       |

**RDB和AOF如何做选择**

小孩子才做选择，我全都要，你单独用RDB你会丢失很多数据，你单独用AOF你数据恢复没RDB来的快。

恢复时第一时间用RDB恢复，然后AOF做数据补全

### 复制

#### 主从复制⭐

**主从复制过程** [参考](https://blog.csdn.net/qq_37806753/article/details/112020983) [参考](https://my.oschina.net/u/2407208/blog/3009249)

从Redis2.8开始，使用`PSYNC`替代`SYNC`进行复制，周期性地确认每次复制的数据量

- 初次复制：**完整重同步**
  - master 启动一个后台线程生成 `RDB` 文件，同时将从客户端新收到的所有写命令缓存在内存中。
  - `RDB` 文件生成完毕后， master 会将文件发给 slave
  - master 将内存中缓存的写命令继续发送到 slave，由 slave 继续同步数据。

- 断线重连：**部分重同步**

  - master 在内存中有一个复制积压缓冲区，复制时master和slave都会保存复制偏移量 `offset` 及运行id `runid`
  - slave检查runid是否一致
    - 若runid不一致，则进行全量复制
    - 若runid一致，则让 master 从上次的 offset 继续复制。但若没有找到对应的 offset ，则进行全量复制。

### 哨兵

#### 哨兵原理⭐

**哨兵作用及工作过程** [参考](https://baijiahao.baidu.com/s?id=1668892272814163457&wfr=spider&for=pc)

一个哨兵也是一台 Redis 服务器，只是不对外提供任何服务，通常形成哨兵集群。

<img src="https://img-blog.csdnimg.cn/20200115174006561.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly90aGlua3dvbi5ibG9nLmNzZG4ubmV0,size_16,color_FFFFFF,t_70" alt="img" style="zoom: 50%;" />

**1 监控**：不断检查master和slave是否正常运行。（心跳机制，发送 publish sentinel：hello时哨兵报出 sdown）

**2 通知**：当发现被监控的节点出现问题时，向其他哨兵和节点发送通知

- 主观下线：一个哨兵认为节点挂了，之后哨兵集群投票

- 客观下线：半数哨兵认为节点挂了

**3 故障转移**：判定主节点客观下线后，选举新的slave作为master

- 哨兵集群选举主哨兵（每个 sentinel 既是参选者也是投票者）
  - sentinel 同时发送指令(sentinel is-master-down-by-address-port)并且携带上自己竞选次数和 runid
  - 如先接到谁的指令就把票投给谁
- 主哨兵选举新master节点
  - 常在线的
  - 响应快的
  - 最近与主节点交互的节点
  - 优先级
  - offset偏移量
  - runid：越小越老的优先

---

**为什么Redis集群哨兵必须是奇数个且>=3？**

保证选举时的**半数以上规则**

- 奇数：如果是偶数，则有可能出现**两台机器得票相同**的情况（平分投给两台机器）
- 3个及以上节点：如果是2个节点，只要其中1个挂掉，那么剩下的1个的得票数仅有1票即1/2

**为什么Redis集群节点推荐奇数个**  [参考](https://blog.csdn.net/wenyiCodeDog/article/details/106957284) [参考](https://blog.csdn.net/qq32933432/article/details/105785571)



**为什么Redis集群主节点至少3个即至少3主3从** [参考](https://blog.csdn.net/wenyiCodeDog/article/details/106957284) [参考](https://blog.csdn.net/zhangbaoxiang/article/details/107379622)

官方定义，原因未知

#### 主从数据丢失⭐

**哨兵进行主备切换的时候会有数据丢失的可能吗？ **[参考](https://www.nowcoder.com/discuss/203729?type=1)

会，哨兵 + redis 的主从架构是不保证数据零丢失的，只能保证高可用

- **异步复制**
  - master 到 slave 的复制是异步的，所以若数据还没复制到slave时，master发生宕机，便会发生数据丢失
    
  - 恢复后的旧master会当做slave挂到新的master上，删除自身数据，从新master同步数据，原来的数据还是会丢失

- **脑裂**
  - 某个master突然脱离了网络，跟其他slave机器不能连接。此时哨兵可能就会认为master宕机了，然后出新master，导致集群里有**两个master**（网络分区现象）
  - 恢复后的旧master会当做slave挂到新的master上，删除自身数据，从新master同步数据，原来的数据还是会丢失

**如何解决数据丢失的问题？**

数据丢失的问题是不可避免的，但是我们可以尽量减少。

- 对redis服务器

  ```
  min-slaves-to-write 1	//默认0
  min-slaves-max-lag 10	//默认10
  ```

  要求至少有1个slave数据复制和同步的延迟不能超过10秒。反之master不会再接收任何请求。

  可以减小`min-slaves-max-lag`的值，减少故障延迟下接受命令的时间。

- 对于client
  - 采取降级措施，将数据暂时写入本地缓存和磁盘中，在一段时间后重新写入master
  - 将数据写入kafka消息队列，隔一段时间去消费kafka中的数据。

### 集群

#### 集群概述⭐

**Redis是单线程的，如何提高多核CPU的利用率？ / 内存不够怎么办？**

分片（shard）。同一个服务器部署多个Redis的实例，并把他们当作不同的服务器来使用。

**Redis集群如何选择数据库？**

目前无法做数据库选择，默认在0数据库。

**Redis分区/分片有什么缺点？/ 有什么问题**⭐

- **数据丢失……**
- **动态扩容缩容复杂……**
- **备份麻烦**，必须从不同的Redis实例和主机收集RDB / AOF文件
- 不能使用Redis事务
- 涉及多个key的操作通常不会被支持。例如你不能对两个集合求交集，因为他们可能被存储到不同的Redis实例（实际上这种情况也有办法，但是不能直接使用交集指令）。
- 分区使用的粒度是key，不能使用一个非常长的排序key存储一个数据集

#### 集群方案⭐

**你知道有哪些Redis分区实现方案？** [参考](https://zhuanlan.zhihu.com/p/44537690)

**1 客户端分区**

由客户端决定数据会被存储到哪个redis节点或者从哪个redis节点读取

<img src="https://pic1.zhimg.com/80/v2-5566ab468af87c60e47435fbfb3e8004_720w.jpg" alt="img" style="zoom:80%;" />

**优点**

- 不使用第三方中间件
- 容易线性扩展，灵活性强。
- 分区逻辑可控，配置简单，节点之间无关联

**缺点**

- 客户端需要自行维护分发逻辑
- 客户端之间无连接共享，造成连接浪费
- 客户端无法动态增删服务节点

**例子**

`Redis Sharding`，是 `Redis Cluster` 之前业界普遍使用的方法。

---

**2 代理分区**

客户端发送请求到代理组件，由代理组件代理解析客户端的数据，并将请求转发至正确的节点，最后将结果回复给客户端

<img src="https://pic2.zhimg.com/80/v2-0f96f6eccb5a88d842799818e604d099_720w.jpg" alt="img" style="zoom: 50%;" />

**优点**

- 简化客户端的分布式逻辑
- 客户端透明接入，切换成本低
- 代理的转发和存储分离。

**缺点**

多一层代理层，加重了架构部署复杂度和性能损耗。

**例子**

> **Twemproxy**

**Codis** 

Codis 采用了无状态的代理层。对于客户端一切都是透明的；对于上层应用连接 Codis-Proxy 和直接连接原生 Redis-Server 没有区别。Codis 底层会处理请求的转发，不停机的进行数据迁移等工作。

<img src="https://pic3.zhimg.com/80/v2-0c279f53dca700a6ae04c6c91a5b36e2_720w.jpg" alt="img" style="zoom:67%;" />

优点

- 实现了上层 Proxy 和底层 Redis 的高可用、数据分片和自动平衡

- 提供命令行接口和 RESTful API
- 提供监控和管理界面，可以动态添加和删除 Redis 节点。

缺点

- 配置复杂
- 不支持跨机房和多租户
- 不支持鉴权管理部署架构

---

**3 查询路由**（使用）

客户端随机请求任意一个redis节点，并在客户端的帮助下直接重定向到正确的redis节点
                                                                         <img src="https://pic2.zhimg.com/80/v2-dbf6491e8df7f0faff00094bed90976d_720w.jpg" alt="img" style="zoom:50%;" />
**优点**

- 无中心节点，易于扩容/缩容
- 支持高可用和自动故障转移，运维成本低。

**缺点**

- 严重依赖 Redis-trib 工具，缺乏监控管理，需要依赖 Smart Client (维护连接，缓存路由表，MultiOp 和 Pipeline 支持)。
- Failover 节点的检测过慢，不如 中心节点 ZooKeeper 及时。
- Gossip 消息具有一定开销。无法根据统计区分冷热数据。

#### 数据分布⭐

数据分布通常有哈希分区和顺序分区两种方式。Redis Cluster采用**哈希分区**规则，不断优化如下：

**1 节点取余**

使用特定数据，如 Redis 的键或用户ID以及**节点数量 N**：hash（key）% N ，决定数据映射到哪一个节点上。

<img src="https://pic1.zhimg.com/80/v2-4102485a72a278fed8aa5450a99fb8dc_720w.jpg" alt="img" style="zoom:67%;" />

**优点**

简单。

**缺点**

节点数量变化时，映射关系需要重新计算，从而导致数据迁移。一般采用预分区的方式，提前规划好分区数，避免迁移

---

**2 一致性哈希**⭐ [参考](https://blog.csdn.net/weixin_36510400/article/details/105309657) [参考](https://blog.csdn.net/qq_21125183/article/details/90019034)

- 为解决节点取余分区的缺点，构造长度设为**2^32**的Hash环。
- 使用哈希函数`hash（服务器A的IP地址） %  2^32` 确定节点在环的位置
- 数据根据key及哈希函数确定在环的位置，然后**顺时针**找到临接的 Redis 节点并存放于此节点中

<img src="https://i.loli.net/2021/03/19/fBhZvEmaA1QUcFn.png" alt="image-20210319215456888" style="zoom: 67%;" />

**优点**

加减节点时仅影响顺时针相邻的后续节点。

> 一致性哈希的一致性体现在，服务器数量变化时影响的数据—服务器关系不是全量的。[参考](https://www.zhihu.com/question/344111956/answer/813639708)

**缺点**

- 不适合少量节点存储，因为节点变化时将大范围影响哈希环中数据映射 **数据倾斜问题**
- 加减Redis节点会造成哈希环部分数据无法命中？？？

> 因为这些缺点，一些分布式系统采用虚拟槽进行**改进**，比如 Dynamo 系统。

**数据倾斜问题 虚拟节点**

服务节点太少时，容易因为节点分部不均匀而造成数据倾斜问题（数据大部分集中缓存在某台服务器上）

- 对每一个服务节点计算多个哈希，放置多个节点，称为**虚拟节点**。
- 具体做法可以在服务器IP或主机名的后面增加编号来实现。

<img src="https://img-blog.csdnimg.cn/20190509092001537.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzIxMTI1MTgz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" style="zoom: 50%;" />

---

**3 虚拟槽**⭐（使用）

- 使用哈希函数把所有数据映射到一个固定范围的整数集合中，整数定义为 **槽（slot）**。
- 槽是数据管理和迁移的基本单位，每个节点会负责一定数量的槽。采用大范围槽的主要目的是为了方便数据拆分和集群扩展。
- 槽范围是 0 ~ 16383，`slot = CRC16（key）& 16383 `

<img src="https://pic4.zhimg.com/80/v2-b85550cef95e76ceae60b88025f73213_720w.jpg" alt="img" style="zoom: 50%;" />

**优点**

- 很容易添加或者删除节点，只需移动哈希槽即可
- 移动哈希槽并不会使节点停止服务，不会造成集群不可用的状态

### 分布式锁

#### 分布式锁概述⭐

**为什么需要分布式锁** [参考](https://blog.csdn.net/qq_30736263/article/details/104009072)

- 之前学的（java高并发锁-自己的jvm中）是单机锁，保证的是**一个进程中**多线程的并发安全

- 但对分布式下是多进程的，故需要分布式锁保证多进程的并发安全

  例子：分布式下电商超卖 i-- 

**Redis单线程，为什么要用分布式锁 ** [参考](https://www.zhihu.com/question/294599028)

- Redis单线程只能保证一个进程中的并发安全
- 分布式下是多进程的，故还是需要分布式锁保证多进程的并发安全

**分布式、集群、微服务、SOA 之间的区别** [参考](https://blog.csdn.net/yanqun007/article/details/105966022?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522161634231116780269865833%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fblog.%2522%257D&request_id=161634231116780269865833&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~blog~first_rank_v2~rank_v29-1-105966022.pc_v2_rank_blog_default&utm_term=%E5%88%86%E5%B8%83%E5%BC%8F)

微服务肯定是分布式，分布式不一定是微服务

- 分布式：核心就一个字拆。将一个项目拆分成了多个模块，并将这些模块分开部署。
  - 水平拆分：如将三层架构进行拆分，服务器之间通过dubbo等RPC进行进行整合
  - 垂直拆分：项目根据业务进行拆分
- 微服务：可以理解为一种非常细粒度的垂直拆分。各个部分相互独立

#### 分布式锁实现⭐

**1 基于数据库** [参考](https://www.jb51.net/article/184718.htm)

乐观锁、悲观锁。但一般不考……

---

**2 基于Redis** [参考](https://blog.csdn.net/mingongge/article/details/107218291?utm_medium=distribute.pc_relevant.none-task-blog-baidujs_baidulandingword-0&spm=1001.2101.3001.4242)

**获得分布式锁 / redis为什么可以做分布式锁？**

使用命令： `set key value px milliseconds nx`

- 保证原子性：命令替代了 `setnx + expire` 需要分两次执行命令的方式
- 保证互斥性：set()加入了NX参数，如果key存在，则加锁失败
- 保证不会死锁：设置了过期时间，即使**客户宕机**没有解锁，也能释放锁，保证后续其他客户端能加锁
- 保证容错性：采用 Redlock 算法，**Redis宕机**也能保持锁

**释放分布式锁**

使用命令：`delete key`

获取锁的 set 命令中的 value 具有唯一性，可以使用`UUID.randomUUID().toString()`生成，用来标识锁是哪个请求加的。delete 命令会获取锁对应的value值，检查是否与请求id相等，如果相等则解锁（删除key）。

**存在的问题**

如果存储key的节点宕机，则可能丢失锁，导致出现多个客户端持有锁

- 客户端A从master获取到锁
- 在master将锁同步到slave之前，master宕掉了（Redis的主从同步通常是异步的）。
- 主从切换，slave节点被晋级为master节点
- 客户端B取得了被客户端A之前锁住的资源。

**解决方法 / Redlock算法 / 集群分布式锁** [参考](https://blog.csdn.net/weixin_33728708/article/details/92535168)

- 获取当前时间戳，单位是毫秒；

- 轮流尝试在每个 master 节点上创建锁 `set key value px milliseconds nx`

  > 在这一步里，客户端在每个master上请求锁时，会有一个和总的锁释放时间相比小的多的超时时间。比如如果锁自动释放时间是10秒钟，那每个节点锁请求的超时时间可能是5-50毫秒的范围，这个可以防止一个客户端在某个宕掉的master节点上阻塞过长时间，如果一个master节点不可用了，我们应该尽快尝试下一个master节点。

- 若大多数节点锁建立成功且总建立时间小于锁释放时间，则建立成功。此时锁释放时间为最初锁释放时间减去锁建立时间；

- 如果锁建立失败，则依次释放之前建立的锁

**分布式锁问题总结**

- Java宕机：Redis有设超时时间
- Redis宕机：Redlock算法
- Redis分布式锁续期：只要客户端加锁成功，就会启动一个**watch dog看门狗**。他是一个后台线程，会每隔10秒检查一下，如果客户端还持有锁key，那么就会不断的延长锁key的生存时间。

**Redisson框架**

> Redisson是一个在Redis的基础上实现的Java驻内存数据网格（In-Memory Data Grid）。它不仅提供了一系列的分布式的Java常用对象，还实现了可重入锁（Reentrant Lock）、公平锁（Fair Lock、联锁（MultiLock）、 红锁（RedLock）、 读写锁（ReadWriteLock）等，还提供了许多分布式服务。

---

**3 基于Zookeeper **[参考](https://blog.csdn.net/kongmin_123/article/details/82081953)

ZooKeeper是一个为分布式应用提供一致性服务的开源组件，内部是一个分层的文件系统目录结构。

**获得分布式锁**

<img src="https://img-blog.csdn.net/20180826165509543?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2tvbmdtaW5fMTIz/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="img" style="zoom:67%;" />

- ZooKeeper内部是一个分层的**文件系统目录结构**，故先创建一个持久节点
- 在持久节点下创建**临时顺序节点**，判断自己创建的节点顺序是否最靠前
  - 如果是，则成功获得锁。 
  - 如果不是，则向靠前的次节点注册Watcher，用于监听次节点是否存在。当次节点删除后会立即收到通知

**释放分布式锁**

- 任务完成，客户端显示释放：调用删除临时顺序节点的指令
- 任务执行过程中，客户端崩溃：根据临时节点的特性，其会随之自动删除。 

**优点**

具备高可用、可重入、阻塞锁特性，可解决失效死锁问题。

**缺点**

因为需要频繁的创建和删除节点，性能上不如Redis方式。
